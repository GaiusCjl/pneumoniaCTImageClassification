PyTorch Version:  1.5.0+cu101
Torchvision Version:  0.6.0+cu101
Downloading: "https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth
100%
104M/104M [00:16<00:00, 6.64MB/s]

Inception3(
  (Conv2d_1a_3x3): BasicConv2d(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2a_3x3): BasicConv2d(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2b_3x3): BasicConv2d(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_3b_1x1): BasicConv2d(
    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_4a_3x3): BasicConv2d(
    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Mixed_5b): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5c): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5d): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6a): InceptionB(
    (branch3x3): BasicConv2d(
      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6b): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6c): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6d): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6e): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (AuxLogits): InceptionAux(
    (conv0): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1): BasicConv2d(
      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc): Linear(in_features=768, out_features=3, bias=True)
  )
  (Mixed_7a): InceptionD(
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7b): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7c): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fc): Linear(in_features=2048, out_features=3, bias=True)
)
Initializing Datasets and Dataloaders...
Params to learn:
	 Conv2d_1a_3x3.conv.weight
	 Conv2d_1a_3x3.bn.weight
	 Conv2d_1a_3x3.bn.bias
	 Conv2d_2a_3x3.conv.weight
	 Conv2d_2a_3x3.bn.weight
	 Conv2d_2a_3x3.bn.bias
	 Conv2d_2b_3x3.conv.weight
	 Conv2d_2b_3x3.bn.weight
	 Conv2d_2b_3x3.bn.bias
	 Conv2d_3b_1x1.conv.weight
	 Conv2d_3b_1x1.bn.weight
	 Conv2d_3b_1x1.bn.bias
	 Conv2d_4a_3x3.conv.weight
	 Conv2d_4a_3x3.bn.weight
	 Conv2d_4a_3x3.bn.bias
	 Mixed_5b.branch1x1.conv.weight
	 Mixed_5b.branch1x1.bn.weight
	 Mixed_5b.branch1x1.bn.bias
	 Mixed_5b.branch5x5_1.conv.weight
	 Mixed_5b.branch5x5_1.bn.weight
	 Mixed_5b.branch5x5_1.bn.bias
	 Mixed_5b.branch5x5_2.conv.weight
	 Mixed_5b.branch5x5_2.bn.weight
	 Mixed_5b.branch5x5_2.bn.bias
	 Mixed_5b.branch3x3dbl_1.conv.weight
	 Mixed_5b.branch3x3dbl_1.bn.weight
	 Mixed_5b.branch3x3dbl_1.bn.bias
	 Mixed_5b.branch3x3dbl_2.conv.weight
	 Mixed_5b.branch3x3dbl_2.bn.weight
	 Mixed_5b.branch3x3dbl_2.bn.bias
	 Mixed_5b.branch3x3dbl_3.conv.weight
	 Mixed_5b.branch3x3dbl_3.bn.weight
	 Mixed_5b.branch3x3dbl_3.bn.bias
	 Mixed_5b.branch_pool.conv.weight
	 Mixed_5b.branch_pool.bn.weight
	 Mixed_5b.branch_pool.bn.bias
	 Mixed_5c.branch1x1.conv.weight
	 Mixed_5c.branch1x1.bn.weight
	 Mixed_5c.branch1x1.bn.bias
	 Mixed_5c.branch5x5_1.conv.weight
	 Mixed_5c.branch5x5_1.bn.weight
	 Mixed_5c.branch5x5_1.bn.bias
	 Mixed_5c.branch5x5_2.conv.weight
	 Mixed_5c.branch5x5_2.bn.weight
	 Mixed_5c.branch5x5_2.bn.bias
	 Mixed_5c.branch3x3dbl_1.conv.weight
	 Mixed_5c.branch3x3dbl_1.bn.weight
	 Mixed_5c.branch3x3dbl_1.bn.bias
	 Mixed_5c.branch3x3dbl_2.conv.weight
	 Mixed_5c.branch3x3dbl_2.bn.weight
	 Mixed_5c.branch3x3dbl_2.bn.bias
	 Mixed_5c.branch3x3dbl_3.conv.weight
	 Mixed_5c.branch3x3dbl_3.bn.weight
	 Mixed_5c.branch3x3dbl_3.bn.bias
	 Mixed_5c.branch_pool.conv.weight
	 Mixed_5c.branch_pool.bn.weight
	 Mixed_5c.branch_pool.bn.bias
	 Mixed_5d.branch1x1.conv.weight
	 Mixed_5d.branch1x1.bn.weight
	 Mixed_5d.branch1x1.bn.bias
	 Mixed_5d.branch5x5_1.conv.weight
	 Mixed_5d.branch5x5_1.bn.weight
	 Mixed_5d.branch5x5_1.bn.bias
	 Mixed_5d.branch5x5_2.conv.weight
	 Mixed_5d.branch5x5_2.bn.weight
	 Mixed_5d.branch5x5_2.bn.bias
	 Mixed_5d.branch3x3dbl_1.conv.weight
	 Mixed_5d.branch3x3dbl_1.bn.weight
	 Mixed_5d.branch3x3dbl_1.bn.bias
	 Mixed_5d.branch3x3dbl_2.conv.weight
	 Mixed_5d.branch3x3dbl_2.bn.weight
	 Mixed_5d.branch3x3dbl_2.bn.bias
	 Mixed_5d.branch3x3dbl_3.conv.weight
	 Mixed_5d.branch3x3dbl_3.bn.weight
	 Mixed_5d.branch3x3dbl_3.bn.bias
	 Mixed_5d.branch_pool.conv.weight
	 Mixed_5d.branch_pool.bn.weight
	 Mixed_5d.branch_pool.bn.bias
	 Mixed_6a.branch3x3.conv.weight
	 Mixed_6a.branch3x3.bn.weight
	 Mixed_6a.branch3x3.bn.bias
	 Mixed_6a.branch3x3dbl_1.conv.weight
	 Mixed_6a.branch3x3dbl_1.bn.weight
	 Mixed_6a.branch3x3dbl_1.bn.bias
	 Mixed_6a.branch3x3dbl_2.conv.weight
	 Mixed_6a.branch3x3dbl_2.bn.weight
	 Mixed_6a.branch3x3dbl_2.bn.bias
	 Mixed_6a.branch3x3dbl_3.conv.weight
	 Mixed_6a.branch3x3dbl_3.bn.weight
	 Mixed_6a.branch3x3dbl_3.bn.bias
	 Mixed_6b.branch1x1.conv.weight
	 Mixed_6b.branch1x1.bn.weight
	 Mixed_6b.branch1x1.bn.bias
	 Mixed_6b.branch7x7_1.conv.weight
	 Mixed_6b.branch7x7_1.bn.weight
	 Mixed_6b.branch7x7_1.bn.bias
	 Mixed_6b.branch7x7_2.conv.weight
	 Mixed_6b.branch7x7_2.bn.weight
	 Mixed_6b.branch7x7_2.bn.bias
	 Mixed_6b.branch7x7_3.conv.weight
	 Mixed_6b.branch7x7_3.bn.weight
	 Mixed_6b.branch7x7_3.bn.bias
	 Mixed_6b.branch7x7dbl_1.conv.weight
	 Mixed_6b.branch7x7dbl_1.bn.weight
	 Mixed_6b.branch7x7dbl_1.bn.bias
	 Mixed_6b.branch7x7dbl_2.conv.weight
	 Mixed_6b.branch7x7dbl_2.bn.weight
	 Mixed_6b.branch7x7dbl_2.bn.bias
	 Mixed_6b.branch7x7dbl_3.conv.weight
	 Mixed_6b.branch7x7dbl_3.bn.weight
	 Mixed_6b.branch7x7dbl_3.bn.bias
	 Mixed_6b.branch7x7dbl_4.conv.weight
	 Mixed_6b.branch7x7dbl_4.bn.weight
	 Mixed_6b.branch7x7dbl_4.bn.bias
	 Mixed_6b.branch7x7dbl_5.conv.weight
	 Mixed_6b.branch7x7dbl_5.bn.weight
	 Mixed_6b.branch7x7dbl_5.bn.bias
	 Mixed_6b.branch_pool.conv.weight
	 Mixed_6b.branch_pool.bn.weight
	 Mixed_6b.branch_pool.bn.bias
	 Mixed_6c.branch1x1.conv.weight
	 Mixed_6c.branch1x1.bn.weight
	 Mixed_6c.branch1x1.bn.bias
	 Mixed_6c.branch7x7_1.conv.weight
	 Mixed_6c.branch7x7_1.bn.weight
	 Mixed_6c.branch7x7_1.bn.bias
	 Mixed_6c.branch7x7_2.conv.weight
	 Mixed_6c.branch7x7_2.bn.weight
	 Mixed_6c.branch7x7_2.bn.bias
	 Mixed_6c.branch7x7_3.conv.weight
	 Mixed_6c.branch7x7_3.bn.weight
	 Mixed_6c.branch7x7_3.bn.bias
	 Mixed_6c.branch7x7dbl_1.conv.weight
	 Mixed_6c.branch7x7dbl_1.bn.weight
	 Mixed_6c.branch7x7dbl_1.bn.bias
	 Mixed_6c.branch7x7dbl_2.conv.weight
	 Mixed_6c.branch7x7dbl_2.bn.weight
	 Mixed_6c.branch7x7dbl_2.bn.bias
	 Mixed_6c.branch7x7dbl_3.conv.weight
	 Mixed_6c.branch7x7dbl_3.bn.weight
	 Mixed_6c.branch7x7dbl_3.bn.bias
	 Mixed_6c.branch7x7dbl_4.conv.weight
	 Mixed_6c.branch7x7dbl_4.bn.weight
	 Mixed_6c.branch7x7dbl_4.bn.bias
	 Mixed_6c.branch7x7dbl_5.conv.weight
	 Mixed_6c.branch7x7dbl_5.bn.weight
	 Mixed_6c.branch7x7dbl_5.bn.bias
	 Mixed_6c.branch_pool.conv.weight
	 Mixed_6c.branch_pool.bn.weight
	 Mixed_6c.branch_pool.bn.bias
	 Mixed_6d.branch1x1.conv.weight
	 Mixed_6d.branch1x1.bn.weight
	 Mixed_6d.branch1x1.bn.bias
	 Mixed_6d.branch7x7_1.conv.weight
	 Mixed_6d.branch7x7_1.bn.weight
	 Mixed_6d.branch7x7_1.bn.bias
	 Mixed_6d.branch7x7_2.conv.weight
	 Mixed_6d.branch7x7_2.bn.weight
	 Mixed_6d.branch7x7_2.bn.bias
	 Mixed_6d.branch7x7_3.conv.weight
	 Mixed_6d.branch7x7_3.bn.weight
	 Mixed_6d.branch7x7_3.bn.bias
	 Mixed_6d.branch7x7dbl_1.conv.weight
	 Mixed_6d.branch7x7dbl_1.bn.weight
	 Mixed_6d.branch7x7dbl_1.bn.bias
	 Mixed_6d.branch7x7dbl_2.conv.weight
	 Mixed_6d.branch7x7dbl_2.bn.weight
	 Mixed_6d.branch7x7dbl_2.bn.bias
	 Mixed_6d.branch7x7dbl_3.conv.weight
	 Mixed_6d.branch7x7dbl_3.bn.weight
	 Mixed_6d.branch7x7dbl_3.bn.bias
	 Mixed_6d.branch7x7dbl_4.conv.weight
	 Mixed_6d.branch7x7dbl_4.bn.weight
	 Mixed_6d.branch7x7dbl_4.bn.bias
	 Mixed_6d.branch7x7dbl_5.conv.weight
	 Mixed_6d.branch7x7dbl_5.bn.weight
	 Mixed_6d.branch7x7dbl_5.bn.bias
	 Mixed_6d.branch_pool.conv.weight
	 Mixed_6d.branch_pool.bn.weight
	 Mixed_6d.branch_pool.bn.bias
	 Mixed_6e.branch1x1.conv.weight
	 Mixed_6e.branch1x1.bn.weight
	 Mixed_6e.branch1x1.bn.bias
	 Mixed_6e.branch7x7_1.conv.weight
	 Mixed_6e.branch7x7_1.bn.weight
	 Mixed_6e.branch7x7_1.bn.bias
	 Mixed_6e.branch7x7_2.conv.weight
	 Mixed_6e.branch7x7_2.bn.weight
	 Mixed_6e.branch7x7_2.bn.bias
	 Mixed_6e.branch7x7_3.conv.weight
	 Mixed_6e.branch7x7_3.bn.weight
	 Mixed_6e.branch7x7_3.bn.bias
	 Mixed_6e.branch7x7dbl_1.conv.weight
	 Mixed_6e.branch7x7dbl_1.bn.weight
	 Mixed_6e.branch7x7dbl_1.bn.bias
	 Mixed_6e.branch7x7dbl_2.conv.weight
	 Mixed_6e.branch7x7dbl_2.bn.weight
	 Mixed_6e.branch7x7dbl_2.bn.bias
	 Mixed_6e.branch7x7dbl_3.conv.weight
	 Mixed_6e.branch7x7dbl_3.bn.weight
	 Mixed_6e.branch7x7dbl_3.bn.bias
	 Mixed_6e.branch7x7dbl_4.conv.weight
	 Mixed_6e.branch7x7dbl_4.bn.weight
	 Mixed_6e.branch7x7dbl_4.bn.bias
	 Mixed_6e.branch7x7dbl_5.conv.weight
	 Mixed_6e.branch7x7dbl_5.bn.weight
	 Mixed_6e.branch7x7dbl_5.bn.bias
	 Mixed_6e.branch_pool.conv.weight
	 Mixed_6e.branch_pool.bn.weight
	 Mixed_6e.branch_pool.bn.bias
	 AuxLogits.conv0.conv.weight
	 AuxLogits.conv0.bn.weight
	 AuxLogits.conv0.bn.bias
	 AuxLogits.conv1.conv.weight
	 AuxLogits.conv1.bn.weight
	 AuxLogits.conv1.bn.bias
	 AuxLogits.fc.weight
	 AuxLogits.fc.bias
	 Mixed_7a.branch3x3_1.conv.weight
	 Mixed_7a.branch3x3_1.bn.weight
	 Mixed_7a.branch3x3_1.bn.bias
	 Mixed_7a.branch3x3_2.conv.weight
	 Mixed_7a.branch3x3_2.bn.weight
	 Mixed_7a.branch3x3_2.bn.bias
	 Mixed_7a.branch7x7x3_1.conv.weight
	 Mixed_7a.branch7x7x3_1.bn.weight
	 Mixed_7a.branch7x7x3_1.bn.bias
	 Mixed_7a.branch7x7x3_2.conv.weight
	 Mixed_7a.branch7x7x3_2.bn.weight
	 Mixed_7a.branch7x7x3_2.bn.bias
	 Mixed_7a.branch7x7x3_3.conv.weight
	 Mixed_7a.branch7x7x3_3.bn.weight
	 Mixed_7a.branch7x7x3_3.bn.bias
	 Mixed_7a.branch7x7x3_4.conv.weight
	 Mixed_7a.branch7x7x3_4.bn.weight
	 Mixed_7a.branch7x7x3_4.bn.bias
	 Mixed_7b.branch1x1.conv.weight
	 Mixed_7b.branch1x1.bn.weight
	 Mixed_7b.branch1x1.bn.bias
	 Mixed_7b.branch3x3_1.conv.weight
	 Mixed_7b.branch3x3_1.bn.weight
	 Mixed_7b.branch3x3_1.bn.bias
	 Mixed_7b.branch3x3_2a.conv.weight
	 Mixed_7b.branch3x3_2a.bn.weight
	 Mixed_7b.branch3x3_2a.bn.bias
	 Mixed_7b.branch3x3_2b.conv.weight
	 Mixed_7b.branch3x3_2b.bn.weight
	 Mixed_7b.branch3x3_2b.bn.bias
	 Mixed_7b.branch3x3dbl_1.conv.weight
	 Mixed_7b.branch3x3dbl_1.bn.weight
	 Mixed_7b.branch3x3dbl_1.bn.bias
	 Mixed_7b.branch3x3dbl_2.conv.weight
	 Mixed_7b.branch3x3dbl_2.bn.weight
	 Mixed_7b.branch3x3dbl_2.bn.bias
	 Mixed_7b.branch3x3dbl_3a.conv.weight
	 Mixed_7b.branch3x3dbl_3a.bn.weight
	 Mixed_7b.branch3x3dbl_3a.bn.bias
	 Mixed_7b.branch3x3dbl_3b.conv.weight
	 Mixed_7b.branch3x3dbl_3b.bn.weight
	 Mixed_7b.branch3x3dbl_3b.bn.bias
	 Mixed_7b.branch_pool.conv.weight
	 Mixed_7b.branch_pool.bn.weight
	 Mixed_7b.branch_pool.bn.bias
	 Mixed_7c.branch1x1.conv.weight
	 Mixed_7c.branch1x1.bn.weight
	 Mixed_7c.branch1x1.bn.bias
	 Mixed_7c.branch3x3_1.conv.weight
	 Mixed_7c.branch3x3_1.bn.weight
	 Mixed_7c.branch3x3_1.bn.bias
	 Mixed_7c.branch3x3_2a.conv.weight
	 Mixed_7c.branch3x3_2a.bn.weight
	 Mixed_7c.branch3x3_2a.bn.bias
	 Mixed_7c.branch3x3_2b.conv.weight
	 Mixed_7c.branch3x3_2b.bn.weight
	 Mixed_7c.branch3x3_2b.bn.bias
	 Mixed_7c.branch3x3dbl_1.conv.weight
	 Mixed_7c.branch3x3dbl_1.bn.weight
	 Mixed_7c.branch3x3dbl_1.bn.bias
	 Mixed_7c.branch3x3dbl_2.conv.weight
	 Mixed_7c.branch3x3dbl_2.bn.weight
	 Mixed_7c.branch3x3dbl_2.bn.bias
	 Mixed_7c.branch3x3dbl_3a.conv.weight
	 Mixed_7c.branch3x3dbl_3a.bn.weight
	 Mixed_7c.branch3x3dbl_3a.bn.bias
	 Mixed_7c.branch3x3dbl_3b.conv.weight
	 Mixed_7c.branch3x3dbl_3b.bn.weight
	 Mixed_7c.branch3x3dbl_3b.bn.bias
	 Mixed_7c.branch_pool.conv.weight
	 Mixed_7c.branch_pool.bn.weight
	 Mixed_7c.branch_pool.bn.bias
	 fc.weight
	 fc.bias
Epoch 0/99
----------
train Loss: 1.2445 Acc: 0.6069
val Loss: 0.7660 Acc: 0.5861

Epoch 1/99
----------
train Loss: 1.1091 Acc: 0.6438
val Loss: 1.1061 Acc: 0.6639

Epoch 2/99
----------
train Loss: 1.0848 Acc: 0.6485
val Loss: 0.8320 Acc: 0.6175

Epoch 3/99
----------
train Loss: 1.0117 Acc: 0.6885
val Loss: 0.9270 Acc: 0.6507

Epoch 4/99
----------
train Loss: 0.9682 Acc: 0.7040
val Loss: 0.5481 Acc: 0.7334

Epoch 5/99
----------
train Loss: 0.9539 Acc: 0.7111
val Loss: 0.5217 Acc: 0.7682

Epoch 6/99
----------
train Loss: 0.9102 Acc: 0.7290
val Loss: 0.5394 Acc: 0.7765

Epoch 7/99
----------
train Loss: 0.9202 Acc: 0.7206
val Loss: 0.5856 Acc: 0.7401

Epoch 8/99
----------
train Loss: 0.8833 Acc: 0.7298
val Loss: 0.4801 Acc: 0.7964

Epoch 9/99
----------
train Loss: 0.9023 Acc: 0.7328
val Loss: 0.5103 Acc: 0.7666

Epoch 10/99
----------
train Loss: 0.8574 Acc: 0.7454
val Loss: 0.6852 Acc: 0.7268

Epoch 11/99
----------
train Loss: 0.8765 Acc: 0.7328
val Loss: 0.6809 Acc: 0.6573

Epoch 12/99
----------
train Loss: 0.8491 Acc: 0.7452
val Loss: 0.5723 Acc: 0.7649

Epoch 13/99
----------
train Loss: 0.8316 Acc: 0.7462
val Loss: 0.5366 Acc: 0.7599

Epoch 14/99
----------
train Loss: 0.8220 Acc: 0.7542
val Loss: 0.4657 Acc: 0.7930

Epoch 15/99
----------
train Loss: 0.8054 Acc: 0.7643
val Loss: 0.5027 Acc: 0.7732

Epoch 16/99
----------
train Loss: 0.7972 Acc: 0.7566
val Loss: 0.5994 Acc: 0.7682

Epoch 17/99
----------
train Loss: 0.7924 Acc: 0.7578
val Loss: 0.5722 Acc: 0.7417

Epoch 18/99
----------
train Loss: 0.8122 Acc: 0.7572
val Loss: 0.5251 Acc: 0.7450

Epoch 19/99
----------
train Loss: 0.7989 Acc: 0.7588
val Loss: 0.4347 Acc: 0.7997

Epoch 20/99
----------
train Loss: 0.7767 Acc: 0.7676
val Loss: 0.6570 Acc: 0.7185

Epoch 21/99
----------
train Loss: 0.7772 Acc: 0.7706
val Loss: 0.6103 Acc: 0.7219

Epoch 22/99
----------
train Loss: 0.7814 Acc: 0.7635
val Loss: 0.5613 Acc: 0.7103

Epoch 23/99
----------
train Loss: 0.7785 Acc: 0.7666
val Loss: 0.5079 Acc: 0.7632

Epoch 24/99
----------
train Loss: 0.7506 Acc: 0.7763
val Loss: 0.4913 Acc: 0.7699

Epoch 25/99
----------
train Loss: 0.7527 Acc: 0.7781
val Loss: 0.4870 Acc: 0.7864

Epoch 26/99
----------
train Loss: 0.7679 Acc: 0.7676
val Loss: 0.5172 Acc: 0.7781

Epoch 27/99
----------
train Loss: 0.7341 Acc: 0.7783
val Loss: 0.4398 Acc: 0.7947

Epoch 28/99
----------
train Loss: 0.7412 Acc: 0.7800
val Loss: 0.4425 Acc: 0.7947

Epoch 29/99
----------
train Loss: 0.7346 Acc: 0.7830
val Loss: 0.4641 Acc: 0.7864

Epoch 30/99
----------
train Loss: 0.7391 Acc: 0.7773
val Loss: 0.5635 Acc: 0.7599

Epoch 31/99
----------
train Loss: 0.7491 Acc: 0.7688
val Loss: 0.5597 Acc: 0.7550

Epoch 32/99
----------
train Loss: 0.7336 Acc: 0.7846
val Loss: 0.5774 Acc: 0.7666

Epoch 33/99
----------
train Loss: 0.7424 Acc: 0.7763
val Loss: 0.4243 Acc: 0.8113

Epoch 34/99
----------
train Loss: 0.7373 Acc: 0.7747
val Loss: 0.4685 Acc: 0.7914

Epoch 35/99
----------
train Loss: 0.7361 Acc: 0.7828
val Loss: 0.4340 Acc: 0.8046

Epoch 36/99
----------
train Loss: 0.7339 Acc: 0.7727
val Loss: 0.4455 Acc: 0.7947

Epoch 37/99
----------
train Loss: 0.7361 Acc: 0.7820
val Loss: 0.4352 Acc: 0.8046

Epoch 38/99
----------
train Loss: 0.7114 Acc: 0.7806
val Loss: 0.3927 Acc: 0.8179

Epoch 39/99
----------
train Loss: 0.7246 Acc: 0.7820
val Loss: 0.4859 Acc: 0.7765

Epoch 40/99
----------
train Loss: 0.7073 Acc: 0.7877
val Loss: 0.4565 Acc: 0.7831

Epoch 41/99
----------
train Loss: 0.7172 Acc: 0.7836
val Loss: 0.5495 Acc: 0.7566

Epoch 42/99
----------
train Loss: 0.7077 Acc: 0.7814
val Loss: 0.4204 Acc: 0.7964

Epoch 43/99
----------
train Loss: 0.7147 Acc: 0.7824
val Loss: 0.5533 Acc: 0.7517

Epoch 44/99
----------
train Loss: 0.7094 Acc: 0.7877
val Loss: 0.4489 Acc: 0.7897

Epoch 45/99
----------
train Loss: 0.7027 Acc: 0.7885
val Loss: 0.5229 Acc: 0.7483

Epoch 46/99
----------
train Loss: 0.7148 Acc: 0.7861
val Loss: 0.4901 Acc: 0.7831

Epoch 47/99
----------
train Loss: 0.7154 Acc: 0.7840
val Loss: 0.4534 Acc: 0.7914

Epoch 48/99
----------
train Loss: 0.7035 Acc: 0.7836
val Loss: 0.5271 Acc: 0.7649

Epoch 49/99
----------
train Loss: 0.6983 Acc: 0.7885
val Loss: 0.4509 Acc: 0.7831

Epoch 50/99
----------
train Loss: 0.6976 Acc: 0.7928
val Loss: 0.5046 Acc: 0.7732

Epoch 51/99
----------
train Loss: 0.6942 Acc: 0.7838
val Loss: 0.4382 Acc: 0.7997

Epoch 52/99
----------
train Loss: 0.6892 Acc: 0.7859
val Loss: 0.5356 Acc: 0.7434

Epoch 53/99
----------
train Loss: 0.7075 Acc: 0.7863
val Loss: 0.4481 Acc: 0.7897

Epoch 54/99
----------
train Loss: 0.7005 Acc: 0.7867
val Loss: 0.4254 Acc: 0.7947

Epoch 55/99
----------
train Loss: 0.6846 Acc: 0.7954
val Loss: 0.4074 Acc: 0.8079

Epoch 56/99
----------
train Loss: 0.6738 Acc: 0.7920
val Loss: 0.4340 Acc: 0.8046

Epoch 57/99
----------
train Loss: 0.6926 Acc: 0.7920
val Loss: 0.7757 Acc: 0.6556

Epoch 58/99
----------
train Loss: 0.6896 Acc: 0.7907
val Loss: 0.4590 Acc: 0.7914

Epoch 59/99
----------
train Loss: 0.6801 Acc: 0.7891
val Loss: 0.4190 Acc: 0.7947

Epoch 60/99
----------
train Loss: 0.6806 Acc: 0.7968
val Loss: 0.4402 Acc: 0.8013

Epoch 61/99
----------
train Loss: 0.6775 Acc: 0.7911
val Loss: 0.4276 Acc: 0.7930

Epoch 62/99
----------
train Loss: 0.6821 Acc: 0.7863
val Loss: 0.4171 Acc: 0.8079

Epoch 63/99
----------
train Loss: 0.6690 Acc: 0.7948
val Loss: 0.4808 Acc: 0.7947

Epoch 64/99
----------
train Loss: 0.6655 Acc: 0.7974
val Loss: 0.4850 Acc: 0.7682

Epoch 65/99
----------
train Loss: 0.6866 Acc: 0.7913
val Loss: 0.4307 Acc: 0.8096

Epoch 66/99
----------
train Loss: 0.6747 Acc: 0.7899
val Loss: 0.4727 Acc: 0.7798

Epoch 67/99
----------
train Loss: 0.6675 Acc: 0.7993
val Loss: 0.6400 Acc: 0.7268

Epoch 68/99
----------
train Loss: 0.6803 Acc: 0.7972
val Loss: 0.4694 Acc: 0.7848

Epoch 69/99
----------
train Loss: 0.6552 Acc: 0.8056
val Loss: 0.4156 Acc: 0.8245

Epoch 70/99
----------
train Loss: 0.6624 Acc: 0.7995
val Loss: 0.4707 Acc: 0.7964

Epoch 71/99
----------
train Loss: 0.6815 Acc: 0.7907
val Loss: 0.4463 Acc: 0.8030

Epoch 72/99
----------
train Loss: 0.6677 Acc: 0.7960
val Loss: 0.4075 Acc: 0.8046

Epoch 73/99
----------
train Loss: 0.6585 Acc: 0.8011
val Loss: 0.5248 Acc: 0.7616

Epoch 74/99
----------
train Loss: 0.6656 Acc: 0.7940
val Loss: 0.4646 Acc: 0.7930

Epoch 75/99
----------
train Loss: 0.6571 Acc: 0.7993
val Loss: 0.4028 Acc: 0.8096

Epoch 76/99
----------
train Loss: 0.6659 Acc: 0.7987
val Loss: 0.5395 Acc: 0.7699

Epoch 77/99
----------
train Loss: 0.6622 Acc: 0.7938
val Loss: 0.4158 Acc: 0.8113

Epoch 78/99
----------
train Loss: 0.6435 Acc: 0.7974
val Loss: 0.4408 Acc: 0.8046

Epoch 79/99
----------
train Loss: 0.6514 Acc: 0.7950
val Loss: 0.4226 Acc: 0.8046

Epoch 80/99
----------
train Loss: 0.6545 Acc: 0.8041
val Loss: 0.4272 Acc: 0.8063

Epoch 81/99
----------
train Loss: 0.6648 Acc: 0.7926
val Loss: 0.5150 Acc: 0.7649

Epoch 82/99
----------
train Loss: 0.6529 Acc: 0.8039
val Loss: 0.3613 Acc: 0.8262

Epoch 83/99
----------
train Loss: 0.6598 Acc: 0.7930
val Loss: 0.4081 Acc: 0.8013

Epoch 84/99
----------
train Loss: 0.6403 Acc: 0.8011
val Loss: 0.4715 Acc: 0.8063

Epoch 85/99
----------
train Loss: 0.6560 Acc: 0.7972
val Loss: 0.4202 Acc: 0.8113

Epoch 86/99
----------
train Loss: 0.6438 Acc: 0.7978
val Loss: 0.4648 Acc: 0.8063

Epoch 87/99
----------
train Loss: 0.6431 Acc: 0.8048
val Loss: 0.5060 Acc: 0.7831

Epoch 88/99
----------
train Loss: 0.6487 Acc: 0.8074
val Loss: 0.4987 Acc: 0.7632

Epoch 89/99
----------
train Loss: 0.6440 Acc: 0.8023
val Loss: 0.6162 Acc: 0.7401

Epoch 90/99
----------
train Loss: 0.6508 Acc: 0.7987
val Loss: 0.4343 Acc: 0.8113

Epoch 91/99
----------
train Loss: 0.6343 Acc: 0.8050
val Loss: 0.6352 Acc: 0.7351

Epoch 92/99
----------
train Loss: 0.6463 Acc: 0.7985
val Loss: 0.3873 Acc: 0.8212

Epoch 93/99
----------
train Loss: 0.6483 Acc: 0.8013
val Loss: 0.4026 Acc: 0.8179

Epoch 94/99
----------
train Loss: 0.6468 Acc: 0.8007
val Loss: 0.3907 Acc: 0.8262

Epoch 95/99
----------
train Loss: 0.6449 Acc: 0.8025
val Loss: 0.4132 Acc: 0.8063

Epoch 96/99
----------
train Loss: 0.6349 Acc: 0.8064
val Loss: 0.3967 Acc: 0.8146

Epoch 97/99
----------
train Loss: 0.6252 Acc: 0.8084
val Loss: 0.4705 Acc: 0.8079

Epoch 98/99
----------
train Loss: 0.6456 Acc: 0.8041
val Loss: 0.4439 Acc: 0.8030

Epoch 99/99
----------
train Loss: 0.6452 Acc: 0.8066
val Loss: 0.4223 Acc: 0.8096

Training complete in 171m 33s
Best val Acc: 0.826159