PyTorch Version:  1.5.0+cu101
Torchvision Version:  0.6.0+cu101
load  /content/drive/My Drive/modelTestUploadGoogle/models/inception_SGD_bs16_ep220.pkl  model parameters.

Inception3(
  (Conv2d_1a_3x3): BasicConv2d(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2a_3x3): BasicConv2d(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2b_3x3): BasicConv2d(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_3b_1x1): BasicConv2d(
    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_4a_3x3): BasicConv2d(
    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Mixed_5b): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5c): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5d): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6a): InceptionB(
    (branch3x3): BasicConv2d(
      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6b): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6c): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6d): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6e): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (AuxLogits): InceptionAux(
    (conv0): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1): BasicConv2d(
      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc): Linear(in_features=768, out_features=3, bias=True)
  )
  (Mixed_7a): InceptionD(
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7b): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7c): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fc): Linear(in_features=2048, out_features=3, bias=True)
)
Initializing Datasets and Dataloaders...
Params to learn:
	 Conv2d_1a_3x3.conv.weight
	 Conv2d_1a_3x3.bn.weight
	 Conv2d_1a_3x3.bn.bias
	 Conv2d_2a_3x3.conv.weight
	 Conv2d_2a_3x3.bn.weight
	 Conv2d_2a_3x3.bn.bias
	 Conv2d_2b_3x3.conv.weight
	 Conv2d_2b_3x3.bn.weight
	 Conv2d_2b_3x3.bn.bias
	 Conv2d_3b_1x1.conv.weight
	 Conv2d_3b_1x1.bn.weight
	 Conv2d_3b_1x1.bn.bias
	 Conv2d_4a_3x3.conv.weight
	 Conv2d_4a_3x3.bn.weight
	 Conv2d_4a_3x3.bn.bias
	 Mixed_5b.branch1x1.conv.weight
	 Mixed_5b.branch1x1.bn.weight
	 Mixed_5b.branch1x1.bn.bias
	 Mixed_5b.branch5x5_1.conv.weight
	 Mixed_5b.branch5x5_1.bn.weight
	 Mixed_5b.branch5x5_1.bn.bias
	 Mixed_5b.branch5x5_2.conv.weight
	 Mixed_5b.branch5x5_2.bn.weight
	 Mixed_5b.branch5x5_2.bn.bias
	 Mixed_5b.branch3x3dbl_1.conv.weight
	 Mixed_5b.branch3x3dbl_1.bn.weight
	 Mixed_5b.branch3x3dbl_1.bn.bias
	 Mixed_5b.branch3x3dbl_2.conv.weight
	 Mixed_5b.branch3x3dbl_2.bn.weight
	 Mixed_5b.branch3x3dbl_2.bn.bias
	 Mixed_5b.branch3x3dbl_3.conv.weight
	 Mixed_5b.branch3x3dbl_3.bn.weight
	 Mixed_5b.branch3x3dbl_3.bn.bias
	 Mixed_5b.branch_pool.conv.weight
	 Mixed_5b.branch_pool.bn.weight
	 Mixed_5b.branch_pool.bn.bias
	 Mixed_5c.branch1x1.conv.weight
	 Mixed_5c.branch1x1.bn.weight
	 Mixed_5c.branch1x1.bn.bias
	 Mixed_5c.branch5x5_1.conv.weight
	 Mixed_5c.branch5x5_1.bn.weight
	 Mixed_5c.branch5x5_1.bn.bias
	 Mixed_5c.branch5x5_2.conv.weight
	 Mixed_5c.branch5x5_2.bn.weight
	 Mixed_5c.branch5x5_2.bn.bias
	 Mixed_5c.branch3x3dbl_1.conv.weight
	 Mixed_5c.branch3x3dbl_1.bn.weight
	 Mixed_5c.branch3x3dbl_1.bn.bias
	 Mixed_5c.branch3x3dbl_2.conv.weight
	 Mixed_5c.branch3x3dbl_2.bn.weight
	 Mixed_5c.branch3x3dbl_2.bn.bias
	 Mixed_5c.branch3x3dbl_3.conv.weight
	 Mixed_5c.branch3x3dbl_3.bn.weight
	 Mixed_5c.branch3x3dbl_3.bn.bias
	 Mixed_5c.branch_pool.conv.weight
	 Mixed_5c.branch_pool.bn.weight
	 Mixed_5c.branch_pool.bn.bias
	 Mixed_5d.branch1x1.conv.weight
	 Mixed_5d.branch1x1.bn.weight
	 Mixed_5d.branch1x1.bn.bias
	 Mixed_5d.branch5x5_1.conv.weight
	 Mixed_5d.branch5x5_1.bn.weight
	 Mixed_5d.branch5x5_1.bn.bias
	 Mixed_5d.branch5x5_2.conv.weight
	 Mixed_5d.branch5x5_2.bn.weight
	 Mixed_5d.branch5x5_2.bn.bias
	 Mixed_5d.branch3x3dbl_1.conv.weight
	 Mixed_5d.branch3x3dbl_1.bn.weight
	 Mixed_5d.branch3x3dbl_1.bn.bias
	 Mixed_5d.branch3x3dbl_2.conv.weight
	 Mixed_5d.branch3x3dbl_2.bn.weight
	 Mixed_5d.branch3x3dbl_2.bn.bias
	 Mixed_5d.branch3x3dbl_3.conv.weight
	 Mixed_5d.branch3x3dbl_3.bn.weight
	 Mixed_5d.branch3x3dbl_3.bn.bias
	 Mixed_5d.branch_pool.conv.weight
	 Mixed_5d.branch_pool.bn.weight
	 Mixed_5d.branch_pool.bn.bias
	 Mixed_6a.branch3x3.conv.weight
	 Mixed_6a.branch3x3.bn.weight
	 Mixed_6a.branch3x3.bn.bias
	 Mixed_6a.branch3x3dbl_1.conv.weight
	 Mixed_6a.branch3x3dbl_1.bn.weight
	 Mixed_6a.branch3x3dbl_1.bn.bias
	 Mixed_6a.branch3x3dbl_2.conv.weight
	 Mixed_6a.branch3x3dbl_2.bn.weight
	 Mixed_6a.branch3x3dbl_2.bn.bias
	 Mixed_6a.branch3x3dbl_3.conv.weight
	 Mixed_6a.branch3x3dbl_3.bn.weight
	 Mixed_6a.branch3x3dbl_3.bn.bias
	 Mixed_6b.branch1x1.conv.weight
	 Mixed_6b.branch1x1.bn.weight
	 Mixed_6b.branch1x1.bn.bias
	 Mixed_6b.branch7x7_1.conv.weight
	 Mixed_6b.branch7x7_1.bn.weight
	 Mixed_6b.branch7x7_1.bn.bias
	 Mixed_6b.branch7x7_2.conv.weight
	 Mixed_6b.branch7x7_2.bn.weight
	 Mixed_6b.branch7x7_2.bn.bias
	 Mixed_6b.branch7x7_3.conv.weight
	 Mixed_6b.branch7x7_3.bn.weight
	 Mixed_6b.branch7x7_3.bn.bias
	 Mixed_6b.branch7x7dbl_1.conv.weight
	 Mixed_6b.branch7x7dbl_1.bn.weight
	 Mixed_6b.branch7x7dbl_1.bn.bias
	 Mixed_6b.branch7x7dbl_2.conv.weight
	 Mixed_6b.branch7x7dbl_2.bn.weight
	 Mixed_6b.branch7x7dbl_2.bn.bias
	 Mixed_6b.branch7x7dbl_3.conv.weight
	 Mixed_6b.branch7x7dbl_3.bn.weight
	 Mixed_6b.branch7x7dbl_3.bn.bias
	 Mixed_6b.branch7x7dbl_4.conv.weight
	 Mixed_6b.branch7x7dbl_4.bn.weight
	 Mixed_6b.branch7x7dbl_4.bn.bias
	 Mixed_6b.branch7x7dbl_5.conv.weight
	 Mixed_6b.branch7x7dbl_5.bn.weight
	 Mixed_6b.branch7x7dbl_5.bn.bias
	 Mixed_6b.branch_pool.conv.weight
	 Mixed_6b.branch_pool.bn.weight
	 Mixed_6b.branch_pool.bn.bias
	 Mixed_6c.branch1x1.conv.weight
	 Mixed_6c.branch1x1.bn.weight
	 Mixed_6c.branch1x1.bn.bias
	 Mixed_6c.branch7x7_1.conv.weight
	 Mixed_6c.branch7x7_1.bn.weight
	 Mixed_6c.branch7x7_1.bn.bias
	 Mixed_6c.branch7x7_2.conv.weight
	 Mixed_6c.branch7x7_2.bn.weight
	 Mixed_6c.branch7x7_2.bn.bias
	 Mixed_6c.branch7x7_3.conv.weight
	 Mixed_6c.branch7x7_3.bn.weight
	 Mixed_6c.branch7x7_3.bn.bias
	 Mixed_6c.branch7x7dbl_1.conv.weight
	 Mixed_6c.branch7x7dbl_1.bn.weight
	 Mixed_6c.branch7x7dbl_1.bn.bias
	 Mixed_6c.branch7x7dbl_2.conv.weight
	 Mixed_6c.branch7x7dbl_2.bn.weight
	 Mixed_6c.branch7x7dbl_2.bn.bias
	 Mixed_6c.branch7x7dbl_3.conv.weight
	 Mixed_6c.branch7x7dbl_3.bn.weight
	 Mixed_6c.branch7x7dbl_3.bn.bias
	 Mixed_6c.branch7x7dbl_4.conv.weight
	 Mixed_6c.branch7x7dbl_4.bn.weight
	 Mixed_6c.branch7x7dbl_4.bn.bias
	 Mixed_6c.branch7x7dbl_5.conv.weight
	 Mixed_6c.branch7x7dbl_5.bn.weight
	 Mixed_6c.branch7x7dbl_5.bn.bias
	 Mixed_6c.branch_pool.conv.weight
	 Mixed_6c.branch_pool.bn.weight
	 Mixed_6c.branch_pool.bn.bias
	 Mixed_6d.branch1x1.conv.weight
	 Mixed_6d.branch1x1.bn.weight
	 Mixed_6d.branch1x1.bn.bias
	 Mixed_6d.branch7x7_1.conv.weight
	 Mixed_6d.branch7x7_1.bn.weight
	 Mixed_6d.branch7x7_1.bn.bias
	 Mixed_6d.branch7x7_2.conv.weight
	 Mixed_6d.branch7x7_2.bn.weight
	 Mixed_6d.branch7x7_2.bn.bias
	 Mixed_6d.branch7x7_3.conv.weight
	 Mixed_6d.branch7x7_3.bn.weight
	 Mixed_6d.branch7x7_3.bn.bias
	 Mixed_6d.branch7x7dbl_1.conv.weight
	 Mixed_6d.branch7x7dbl_1.bn.weight
	 Mixed_6d.branch7x7dbl_1.bn.bias
	 Mixed_6d.branch7x7dbl_2.conv.weight
	 Mixed_6d.branch7x7dbl_2.bn.weight
	 Mixed_6d.branch7x7dbl_2.bn.bias
	 Mixed_6d.branch7x7dbl_3.conv.weight
	 Mixed_6d.branch7x7dbl_3.bn.weight
	 Mixed_6d.branch7x7dbl_3.bn.bias
	 Mixed_6d.branch7x7dbl_4.conv.weight
	 Mixed_6d.branch7x7dbl_4.bn.weight
	 Mixed_6d.branch7x7dbl_4.bn.bias
	 Mixed_6d.branch7x7dbl_5.conv.weight
	 Mixed_6d.branch7x7dbl_5.bn.weight
	 Mixed_6d.branch7x7dbl_5.bn.bias
	 Mixed_6d.branch_pool.conv.weight
	 Mixed_6d.branch_pool.bn.weight
	 Mixed_6d.branch_pool.bn.bias
	 Mixed_6e.branch1x1.conv.weight
	 Mixed_6e.branch1x1.bn.weight
	 Mixed_6e.branch1x1.bn.bias
	 Mixed_6e.branch7x7_1.conv.weight
	 Mixed_6e.branch7x7_1.bn.weight
	 Mixed_6e.branch7x7_1.bn.bias
	 Mixed_6e.branch7x7_2.conv.weight
	 Mixed_6e.branch7x7_2.bn.weight
	 Mixed_6e.branch7x7_2.bn.bias
	 Mixed_6e.branch7x7_3.conv.weight
	 Mixed_6e.branch7x7_3.bn.weight
	 Mixed_6e.branch7x7_3.bn.bias
	 Mixed_6e.branch7x7dbl_1.conv.weight
	 Mixed_6e.branch7x7dbl_1.bn.weight
	 Mixed_6e.branch7x7dbl_1.bn.bias
	 Mixed_6e.branch7x7dbl_2.conv.weight
	 Mixed_6e.branch7x7dbl_2.bn.weight
	 Mixed_6e.branch7x7dbl_2.bn.bias
	 Mixed_6e.branch7x7dbl_3.conv.weight
	 Mixed_6e.branch7x7dbl_3.bn.weight
	 Mixed_6e.branch7x7dbl_3.bn.bias
	 Mixed_6e.branch7x7dbl_4.conv.weight
	 Mixed_6e.branch7x7dbl_4.bn.weight
	 Mixed_6e.branch7x7dbl_4.bn.bias
	 Mixed_6e.branch7x7dbl_5.conv.weight
	 Mixed_6e.branch7x7dbl_5.bn.weight
	 Mixed_6e.branch7x7dbl_5.bn.bias
	 Mixed_6e.branch_pool.conv.weight
	 Mixed_6e.branch_pool.bn.weight
	 Mixed_6e.branch_pool.bn.bias
	 AuxLogits.conv0.conv.weight
	 AuxLogits.conv0.bn.weight
	 AuxLogits.conv0.bn.bias
	 AuxLogits.conv1.conv.weight
	 AuxLogits.conv1.bn.weight
	 AuxLogits.conv1.bn.bias
	 AuxLogits.fc.weight
	 AuxLogits.fc.bias
	 Mixed_7a.branch3x3_1.conv.weight
	 Mixed_7a.branch3x3_1.bn.weight
	 Mixed_7a.branch3x3_1.bn.bias
	 Mixed_7a.branch3x3_2.conv.weight
	 Mixed_7a.branch3x3_2.bn.weight
	 Mixed_7a.branch3x3_2.bn.bias
	 Mixed_7a.branch7x7x3_1.conv.weight
	 Mixed_7a.branch7x7x3_1.bn.weight
	 Mixed_7a.branch7x7x3_1.bn.bias
	 Mixed_7a.branch7x7x3_2.conv.weight
	 Mixed_7a.branch7x7x3_2.bn.weight
	 Mixed_7a.branch7x7x3_2.bn.bias
	 Mixed_7a.branch7x7x3_3.conv.weight
	 Mixed_7a.branch7x7x3_3.bn.weight
	 Mixed_7a.branch7x7x3_3.bn.bias
	 Mixed_7a.branch7x7x3_4.conv.weight
	 Mixed_7a.branch7x7x3_4.bn.weight
	 Mixed_7a.branch7x7x3_4.bn.bias
	 Mixed_7b.branch1x1.conv.weight
	 Mixed_7b.branch1x1.bn.weight
	 Mixed_7b.branch1x1.bn.bias
	 Mixed_7b.branch3x3_1.conv.weight
	 Mixed_7b.branch3x3_1.bn.weight
	 Mixed_7b.branch3x3_1.bn.bias
	 Mixed_7b.branch3x3_2a.conv.weight
	 Mixed_7b.branch3x3_2a.bn.weight
	 Mixed_7b.branch3x3_2a.bn.bias
	 Mixed_7b.branch3x3_2b.conv.weight
	 Mixed_7b.branch3x3_2b.bn.weight
	 Mixed_7b.branch3x3_2b.bn.bias
	 Mixed_7b.branch3x3dbl_1.conv.weight
	 Mixed_7b.branch3x3dbl_1.bn.weight
	 Mixed_7b.branch3x3dbl_1.bn.bias
	 Mixed_7b.branch3x3dbl_2.conv.weight
	 Mixed_7b.branch3x3dbl_2.bn.weight
	 Mixed_7b.branch3x3dbl_2.bn.bias
	 Mixed_7b.branch3x3dbl_3a.conv.weight
	 Mixed_7b.branch3x3dbl_3a.bn.weight
	 Mixed_7b.branch3x3dbl_3a.bn.bias
	 Mixed_7b.branch3x3dbl_3b.conv.weight
	 Mixed_7b.branch3x3dbl_3b.bn.weight
	 Mixed_7b.branch3x3dbl_3b.bn.bias
	 Mixed_7b.branch_pool.conv.weight
	 Mixed_7b.branch_pool.bn.weight
	 Mixed_7b.branch_pool.bn.bias
	 Mixed_7c.branch1x1.conv.weight
	 Mixed_7c.branch1x1.bn.weight
	 Mixed_7c.branch1x1.bn.bias
	 Mixed_7c.branch3x3_1.conv.weight
	 Mixed_7c.branch3x3_1.bn.weight
	 Mixed_7c.branch3x3_1.bn.bias
	 Mixed_7c.branch3x3_2a.conv.weight
	 Mixed_7c.branch3x3_2a.bn.weight
	 Mixed_7c.branch3x3_2a.bn.bias
	 Mixed_7c.branch3x3_2b.conv.weight
	 Mixed_7c.branch3x3_2b.bn.weight
	 Mixed_7c.branch3x3_2b.bn.bias
	 Mixed_7c.branch3x3dbl_1.conv.weight
	 Mixed_7c.branch3x3dbl_1.bn.weight
	 Mixed_7c.branch3x3dbl_1.bn.bias
	 Mixed_7c.branch3x3dbl_2.conv.weight
	 Mixed_7c.branch3x3dbl_2.bn.weight
	 Mixed_7c.branch3x3dbl_2.bn.bias
	 Mixed_7c.branch3x3dbl_3a.conv.weight
	 Mixed_7c.branch3x3dbl_3a.bn.weight
	 Mixed_7c.branch3x3dbl_3a.bn.bias
	 Mixed_7c.branch3x3dbl_3b.conv.weight
	 Mixed_7c.branch3x3dbl_3b.bn.weight
	 Mixed_7c.branch3x3dbl_3b.bn.bias
	 Mixed_7c.branch_pool.conv.weight
	 Mixed_7c.branch_pool.bn.weight
	 Mixed_7c.branch_pool.bn.bias
	 fc.weight
	 fc.bias
Epoch 0/99
----------
train Loss: 0.1287 Acc: 0.9636
val Loss: 0.3966 Acc: 0.9238

Epoch 1/99
----------
train Loss: 0.1210 Acc: 0.9657
val Loss: 0.4116 Acc: 0.9222

Epoch 2/99
----------
train Loss: 0.1053 Acc: 0.9699
val Loss: 0.4117 Acc: 0.9222

Epoch 3/99
----------
train Loss: 0.1205 Acc: 0.9657
val Loss: 0.3700 Acc: 0.9288

Epoch 4/99
----------
train Loss: 0.1107 Acc: 0.9663
val Loss: 0.4002 Acc: 0.9205

Epoch 5/99
----------
train Loss: 0.0973 Acc: 0.9728
val Loss: 0.3355 Acc: 0.9288

Epoch 6/99
----------
train Loss: 0.1025 Acc: 0.9691
val Loss: 0.3786 Acc: 0.9305

Epoch 7/99
----------
train Loss: 0.1066 Acc: 0.9707
val Loss: 0.3791 Acc: 0.9288

Epoch 8/99
----------
train Loss: 0.1088 Acc: 0.9705
val Loss: 0.3663 Acc: 0.9321

Epoch 9/99
----------
train Loss: 0.1020 Acc: 0.9742
val Loss: 0.3750 Acc: 0.9272

Epoch 10/99
----------
train Loss: 0.1092 Acc: 0.9685
val Loss: 0.3541 Acc: 0.9272

Epoch 11/99
----------
train Loss: 0.1009 Acc: 0.9724
val Loss: 0.3522 Acc: 0.9305

Epoch 12/99
----------
train Loss: 0.0947 Acc: 0.9724
val Loss: 0.3615 Acc: 0.9354

Epoch 13/99
----------
train Loss: 0.0976 Acc: 0.9720
val Loss: 0.3381 Acc: 0.9288

Epoch 14/99
----------
train Loss: 0.0906 Acc: 0.9742
val Loss: 0.3631 Acc: 0.9305

Epoch 15/99
----------
train Loss: 0.0906 Acc: 0.9724
val Loss: 0.3899 Acc: 0.9305

Epoch 16/99
----------
train Loss: 0.0902 Acc: 0.9726
val Loss: 0.3853 Acc: 0.9288

Epoch 17/99
----------
train Loss: 0.0874 Acc: 0.9726
val Loss: 0.3930 Acc: 0.9272

Epoch 18/99
----------
train Loss: 0.0839 Acc: 0.9750
val Loss: 0.4085 Acc: 0.9305

Epoch 19/99
----------
train Loss: 0.0833 Acc: 0.9768
val Loss: 0.4108 Acc: 0.9354

Epoch 20/99
----------
train Loss: 0.0969 Acc: 0.9707
val Loss: 0.3383 Acc: 0.9338

Epoch 21/99
----------
train Loss: 0.0969 Acc: 0.9732
val Loss: 0.3733 Acc: 0.9305

Epoch 22/99
----------
train Loss: 0.0964 Acc: 0.9726
val Loss: 0.3610 Acc: 0.9305

Epoch 23/99
----------
train Loss: 0.0756 Acc: 0.9787
val Loss: 0.3599 Acc: 0.9338

Epoch 24/99
----------
train Loss: 0.0747 Acc: 0.9803
val Loss: 0.3590 Acc: 0.9288

Epoch 25/99
----------
train Loss: 0.1004 Acc: 0.9705
val Loss: 0.3767 Acc: 0.9321

Epoch 26/99
----------
train Loss: 0.0899 Acc: 0.9748
val Loss: 0.3576 Acc: 0.9338

Epoch 27/99
----------
train Loss: 0.0887 Acc: 0.9738
val Loss: 0.4049 Acc: 0.9272

Epoch 28/99
----------
train Loss: 0.0831 Acc: 0.9738
val Loss: 0.3177 Acc: 0.9338

Epoch 29/99
----------
train Loss: 0.0851 Acc: 0.9748
val Loss: 0.3620 Acc: 0.9321

Epoch 30/99
----------
train Loss: 0.0861 Acc: 0.9732
val Loss: 0.3902 Acc: 0.9321

Epoch 31/99
----------
train Loss: 0.0782 Acc: 0.9764
val Loss: 0.3424 Acc: 0.9338

Epoch 32/99
----------
train Loss: 0.0915 Acc: 0.9707
val Loss: 0.3529 Acc: 0.9288

Epoch 33/99
----------
train Loss: 0.0908 Acc: 0.9728
val Loss: 0.3678 Acc: 0.9338

Epoch 34/99
----------
train Loss: 0.0808 Acc: 0.9762
val Loss: 0.3496 Acc: 0.9305

Epoch 35/99
----------
train Loss: 0.0832 Acc: 0.9770
val Loss: 0.3474 Acc: 0.9288

Epoch 36/99
----------
train Loss: 0.0840 Acc: 0.9764
val Loss: 0.3496 Acc: 0.9288

Epoch 37/99
----------
train Loss: 0.0901 Acc: 0.9722
val Loss: 0.3717 Acc: 0.9321

Epoch 38/99
----------
train Loss: 0.0863 Acc: 0.9742
val Loss: 0.3665 Acc: 0.9321

Epoch 39/99
----------
train Loss: 0.0821 Acc: 0.9750
val Loss: 0.3585 Acc: 0.9321

Epoch 40/99
----------
train Loss: 0.0759 Acc: 0.9777
val Loss: 0.3757 Acc: 0.9321

Epoch 41/99
----------
train Loss: 0.0821 Acc: 0.9758
val Loss: 0.3680 Acc: 0.9321

Epoch 42/99
----------
train Loss: 0.0955 Acc: 0.9718
val Loss: 0.3783 Acc: 0.9321

Epoch 43/99
----------
train Loss: 0.0812 Acc: 0.9785
val Loss: 0.3740 Acc: 0.9305

Epoch 44/99
----------
train Loss: 0.0769 Acc: 0.9783
val Loss: 0.3435 Acc: 0.9338

Epoch 45/99
----------
train Loss: 0.0831 Acc: 0.9764
val Loss: 0.3824 Acc: 0.9288

Epoch 46/99
----------
train Loss: 0.0877 Acc: 0.9738
val Loss: 0.3839 Acc: 0.9255

Epoch 47/99
----------
train Loss: 0.0755 Acc: 0.9754
val Loss: 0.3364 Acc: 0.9371

Epoch 48/99
----------
train Loss: 0.0886 Acc: 0.9744
val Loss: 0.3237 Acc: 0.9354

Epoch 49/99
----------
train Loss: 0.0768 Acc: 0.9770
val Loss: 0.3553 Acc: 0.9272

Epoch 50/99
----------
train Loss: 0.0808 Acc: 0.9746
val Loss: 0.3738 Acc: 0.9338

Epoch 51/99
----------
train Loss: 0.0805 Acc: 0.9783
val Loss: 0.3978 Acc: 0.9321

Epoch 52/99
----------
train Loss: 0.0775 Acc: 0.9791
val Loss: 0.3529 Acc: 0.9321

Epoch 53/99
----------
train Loss: 0.0842 Acc: 0.9736
val Loss: 0.3244 Acc: 0.9338

Epoch 54/99
----------
train Loss: 0.0777 Acc: 0.9766
val Loss: 0.3695 Acc: 0.9305

Epoch 55/99
----------
train Loss: 0.0705 Acc: 0.9785
val Loss: 0.3548 Acc: 0.9338

Epoch 56/99
----------
train Loss: 0.0762 Acc: 0.9777
val Loss: 0.3815 Acc: 0.9321

Epoch 57/99
----------
train Loss: 0.0753 Acc: 0.9768
val Loss: 0.3982 Acc: 0.9305

Epoch 58/99
----------
train Loss: 0.0844 Acc: 0.9736
val Loss: 0.3631 Acc: 0.9305

Epoch 59/99
----------
train Loss: 0.0761 Acc: 0.9770
val Loss: 0.3692 Acc: 0.9321

Epoch 60/99
----------
train Loss: 0.0733 Acc: 0.9797
val Loss: 0.3611 Acc: 0.9321

Epoch 61/99
----------
train Loss: 0.0820 Acc: 0.9754
val Loss: 0.3688 Acc: 0.9338

Epoch 62/99
----------
train Loss: 0.0753 Acc: 0.9791
val Loss: 0.3711 Acc: 0.9305

Epoch 63/99
----------
train Loss: 0.0783 Acc: 0.9779
val Loss: 0.3496 Acc: 0.9288

Epoch 64/99
----------
train Loss: 0.0806 Acc: 0.9740
val Loss: 0.3645 Acc: 0.9321

Epoch 65/99
----------
train Loss: 0.0882 Acc: 0.9746
val Loss: 0.3548 Acc: 0.9305

Epoch 66/99
----------
train Loss: 0.0783 Acc: 0.9770
val Loss: 0.3611 Acc: 0.9272

Epoch 67/99
----------
train Loss: 0.0849 Acc: 0.9736
val Loss: 0.3702 Acc: 0.9222

Epoch 68/99
----------
train Loss: 0.0844 Acc: 0.9770
val Loss: 0.3464 Acc: 0.9354

Epoch 69/99
----------
train Loss: 0.0793 Acc: 0.9785
val Loss: 0.3706 Acc: 0.9305

Epoch 70/99
----------
train Loss: 0.0731 Acc: 0.9797
val Loss: 0.4063 Acc: 0.9255

Epoch 71/99
----------
train Loss: 0.0784 Acc: 0.9795
val Loss: 0.3872 Acc: 0.9255

Epoch 72/99
----------
train Loss: 0.0700 Acc: 0.9809
val Loss: 0.4188 Acc: 0.9255

Epoch 73/99
----------
train Loss: 0.0715 Acc: 0.9791
val Loss: 0.3491 Acc: 0.9272

Epoch 74/99
----------
train Loss: 0.0763 Acc: 0.9762
val Loss: 0.3915 Acc: 0.9238

Epoch 75/99
----------
train Loss: 0.0744 Acc: 0.9768
val Loss: 0.3508 Acc: 0.9288

Epoch 76/99
----------
train Loss: 0.0706 Acc: 0.9795
val Loss: 0.3228 Acc: 0.9321

Epoch 77/99
----------
train Loss: 0.0712 Acc: 0.9793
val Loss: 0.3591 Acc: 0.9272

Epoch 78/99
----------
train Loss: 0.0664 Acc: 0.9797
val Loss: 0.2966 Acc: 0.9321

Epoch 79/99
----------
train Loss: 0.0756 Acc: 0.9785
val Loss: 0.3954 Acc: 0.9272

Epoch 80/99
----------
train Loss: 0.0790 Acc: 0.9754
val Loss: 0.3393 Acc: 0.9321

Epoch 81/99
----------
train Loss: 0.0747 Acc: 0.9783
val Loss: 0.3629 Acc: 0.9272

Epoch 82/99
----------
train Loss: 0.0764 Acc: 0.9777
val Loss: 0.3929 Acc: 0.9255

Epoch 83/99
----------
train Loss: 0.0811 Acc: 0.9791
val Loss: 0.3659 Acc: 0.9288

Epoch 84/99
----------
train Loss: 0.0742 Acc: 0.9770
val Loss: 0.3781 Acc: 0.9255

Epoch 85/99
----------
train Loss: 0.0728 Acc: 0.9791
val Loss: 0.3570 Acc: 0.9288

Epoch 86/99
----------
train Loss: 0.0666 Acc: 0.9772
val Loss: 0.3847 Acc: 0.9255

Epoch 87/99
----------
train Loss: 0.0761 Acc: 0.9774
val Loss: 0.3629 Acc: 0.9305

Epoch 88/99
----------
train Loss: 0.0672 Acc: 0.9809
val Loss: 0.3759 Acc: 0.9255

Epoch 89/99
----------
train Loss: 0.0785 Acc: 0.9768
val Loss: 0.3701 Acc: 0.9272

Epoch 90/99
----------
train Loss: 0.0828 Acc: 0.9768
val Loss: 0.3561 Acc: 0.9272

Epoch 91/99
----------
train Loss: 0.0722 Acc: 0.9762
val Loss: 0.3485 Acc: 0.9338

Epoch 92/99
----------
train Loss: 0.0731 Acc: 0.9795
val Loss: 0.3255 Acc: 0.9354

Epoch 93/99
----------
train Loss: 0.0735 Acc: 0.9799
val Loss: 0.3537 Acc: 0.9288

Epoch 94/99
----------
train Loss: 0.0773 Acc: 0.9785
val Loss: 0.3540 Acc: 0.9288

Epoch 95/99
----------
train Loss: 0.0690 Acc: 0.9772
val Loss: 0.3842 Acc: 0.9305

Epoch 96/99
----------
train Loss: 0.0661 Acc: 0.9795
val Loss: 0.3740 Acc: 0.9305

Epoch 97/99
----------
train Loss: 0.0690 Acc: 0.9811
val Loss: 0.3669 Acc: 0.9305

Epoch 98/99
----------
train Loss: 0.0734 Acc: 0.9781
val Loss: 0.3231 Acc: 0.9305

Epoch 99/99
----------
train Loss: 0.0624 Acc: 0.9821
val Loss: 0.3656 Acc: 0.9305

Training complete in 189m 57s
Best val Acc: 0.937086