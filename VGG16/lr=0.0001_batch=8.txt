VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=3, bias=True)
  )
)
Initializing Datasets and Dataloaders...
Params to learn:
	 features.0.weight
	 features.0.bias
	 features.1.weight
	 features.1.bias
	 features.3.weight
	 features.3.bias
	 features.4.weight
	 features.4.bias
	 features.7.weight
	 features.7.bias
	 features.8.weight
	 features.8.bias
	 features.10.weight
	 features.10.bias
	 features.11.weight
	 features.11.bias
	 features.14.weight
	 features.14.bias
	 features.15.weight
	 features.15.bias
	 features.17.weight
	 features.17.bias
	 features.18.weight
	 features.18.bias
	 features.20.weight
	 features.20.bias
	 features.21.weight
	 features.21.bias
	 features.24.weight
	 features.24.bias
	 features.25.weight
	 features.25.bias
	 features.27.weight
	 features.27.bias
	 features.28.weight
	 features.28.bias
	 features.30.weight
	 features.30.bias
	 features.31.weight
	 features.31.bias
	 features.34.weight
	 features.34.bias
	 features.35.weight
	 features.35.bias
	 features.37.weight
	 features.37.bias
	 features.38.weight
	 features.38.bias
	 features.40.weight
	 features.40.bias
	 features.41.weight
	 features.41.bias
	 classifier.0.weight
	 classifier.0.bias
	 classifier.3.weight
	 classifier.3.bias
	 classifier.6.weight
	 classifier.6.bias
Epoch 0/99
----------
train Loss: 0.6925 Acc: 0.7040
val Loss: 0.5024 Acc: 0.8212

Epoch 1/99
----------
train Loss: 0.6053 Acc: 0.7414
val Loss: 0.4475 Acc: 0.8361

Epoch 2/99
----------
train Loss: 0.5782 Acc: 0.7597
val Loss: 0.4415 Acc: 0.8212

Epoch 3/99
----------
train Loss: 0.5503 Acc: 0.7649
val Loss: 0.5725 Acc: 0.8013

Epoch 4/99
----------
train Loss: 0.5479 Acc: 0.7690
val Loss: 0.4944 Acc: 0.7997

Epoch 5/99
----------
train Loss: 0.5284 Acc: 0.7806
val Loss: 0.4612 Acc: 0.8146

Epoch 6/99
----------
train Loss: 0.5111 Acc: 0.7814
val Loss: 0.4441 Acc: 0.8079

Epoch 7/99
----------
train Loss: 0.5148 Acc: 0.7842
val Loss: 0.4561 Acc: 0.8063

Epoch 8/99
----------
train Loss: 0.4946 Acc: 0.7905
val Loss: 0.4349 Acc: 0.8129

Epoch 9/99
----------
train Loss: 0.4897 Acc: 0.7966
val Loss: 0.3953 Acc: 0.8427

Epoch 10/99
----------
train Loss: 0.4915 Acc: 0.7952
val Loss: 0.6570 Acc: 0.7086

Epoch 11/99
----------
train Loss: 0.4839 Acc: 0.8001
val Loss: 0.3808 Acc: 0.8377

Epoch 12/99
----------
train Loss: 0.4742 Acc: 0.7983
val Loss: 0.4287 Acc: 0.8411

Epoch 13/99
----------
train Loss: 0.4715 Acc: 0.8041
val Loss: 0.3900 Acc: 0.8460

Epoch 14/99
----------
train Loss: 0.4618 Acc: 0.8108
val Loss: 0.4115 Acc: 0.8377

Epoch 15/99
----------
train Loss: 0.4661 Acc: 0.8062
val Loss: 0.4062 Acc: 0.8526

Epoch 16/99
----------
train Loss: 0.4551 Acc: 0.8108
val Loss: 0.5263 Acc: 0.7964

Epoch 17/99
----------
train Loss: 0.4524 Acc: 0.8068
val Loss: 0.4958 Acc: 0.8030

Epoch 18/99
----------
train Loss: 0.4457 Acc: 0.8214
val Loss: 0.5806 Acc: 0.7947

Epoch 19/99
----------
train Loss: 0.4389 Acc: 0.8106
val Loss: 0.4948 Acc: 0.8146

Epoch 20/99
----------
train Loss: 0.4350 Acc: 0.8133
val Loss: 0.4001 Acc: 0.8411

Epoch 21/99
----------
train Loss: 0.4339 Acc: 0.8180
val Loss: 0.5114 Acc: 0.7930

Epoch 22/99
----------
train Loss: 0.4197 Acc: 0.8261
val Loss: 0.4475 Acc: 0.8295

Epoch 23/99
----------
train Loss: 0.4132 Acc: 0.8344
val Loss: 0.4296 Acc: 0.8295

Epoch 24/99
----------
train Loss: 0.4122 Acc: 0.8259
val Loss: 0.4969 Acc: 0.8212

Epoch 25/99
----------
train Loss: 0.4038 Acc: 0.8293
val Loss: 0.3956 Acc: 0.8626

Epoch 26/99
----------
train Loss: 0.3881 Acc: 0.8379
val Loss: 0.6976 Acc: 0.8046

Epoch 27/99
----------
train Loss: 0.3928 Acc: 0.8330
val Loss: 0.5808 Acc: 0.8195

Epoch 28/99
----------
train Loss: 0.3856 Acc: 0.8358
val Loss: 0.6397 Acc: 0.7715

Epoch 29/99
----------
train Loss: 0.3937 Acc: 0.8389
val Loss: 0.4190 Acc: 0.8295

Epoch 30/99
----------
train Loss: 0.3716 Acc: 0.8436
val Loss: 0.4272 Acc: 0.8179

Epoch 31/99
----------
train Loss: 0.3858 Acc: 0.8425
val Loss: 0.4268 Acc: 0.8328

Epoch 32/99
----------
train Loss: 0.3791 Acc: 0.8464
val Loss: 0.4535 Acc: 0.8328

Epoch 33/99
----------
train Loss: 0.3677 Acc: 0.8519
val Loss: 0.4212 Acc: 0.8444

Epoch 34/99
----------
train Loss: 0.3638 Acc: 0.8478
val Loss: 0.4726 Acc: 0.8361

Epoch 35/99
----------
train Loss: 0.3524 Acc: 0.8529
val Loss: 0.4157 Acc: 0.8411

Epoch 36/99
----------
train Loss: 0.3581 Acc: 0.8525
val Loss: 0.6385 Acc: 0.8212

Epoch 37/99
----------
train Loss: 0.3559 Acc: 0.8515
val Loss: 0.7302 Acc: 0.7550

Epoch 38/99
----------
train Loss: 0.3486 Acc: 0.8592
val Loss: 0.5111 Acc: 0.8344

Epoch 39/99
----------
train Loss: 0.3476 Acc: 0.8586
val Loss: 0.4251 Acc: 0.8593

Epoch 40/99
----------
train Loss: 0.3360 Acc: 0.8616
val Loss: 0.5086 Acc: 0.8460

Epoch 41/99
----------
train Loss: 0.3284 Acc: 0.8586
val Loss: 0.5044 Acc: 0.8526

Epoch 42/99
----------
train Loss: 0.3236 Acc: 0.8675
val Loss: 0.4621 Acc: 0.8394

Epoch 43/99
----------
train Loss: 0.3339 Acc: 0.8639
val Loss: 0.6933 Acc: 0.7964

Epoch 44/99
----------
train Loss: 0.3111 Acc: 0.8736
val Loss: 0.6687 Acc: 0.8063

Epoch 45/99
----------
train Loss: 0.3255 Acc: 0.8665
val Loss: 0.4365 Acc: 0.8493

Epoch 46/99
----------
train Loss: 0.3132 Acc: 0.8706
val Loss: 0.4251 Acc: 0.8493

Epoch 47/99
----------
train Loss: 0.3101 Acc: 0.8694
val Loss: 0.4097 Acc: 0.8510

Epoch 48/99
----------
train Loss: 0.3010 Acc: 0.8746
val Loss: 0.7800 Acc: 0.7781

Epoch 49/99
----------
train Loss: 0.3007 Acc: 0.8789
val Loss: 0.7615 Acc: 0.7732
