PyTorch Version:  1.5.0+cu101
Torchvision Version:  0.6.0+cu101
Downloading: "https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth
100%
104M/104M [00:01<00:00, 92.4MB/s]

Inception3(
  (Conv2d_1a_3x3): BasicConv2d(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2a_3x3): BasicConv2d(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_2b_3x3): BasicConv2d(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_3b_1x1): BasicConv2d(
    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Conv2d_4a_3x3): BasicConv2d(
    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Mixed_5b): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5c): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_5d): InceptionA(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_1): BasicConv2d(
      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch5x5_2): BasicConv2d(
      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6a): InceptionB(
    (branch3x3): BasicConv2d(
      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3): BasicConv2d(
      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6b): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6c): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6d): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_6e): InceptionC(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7dbl_5): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (AuxLogits): InceptionAux(
    (conv0): BasicConv2d(
      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1): BasicConv2d(
      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc): Linear(in_features=768, out_features=3, bias=True)
  )
  (Mixed_7a): InceptionD(
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2): BasicConv2d(
      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_1): BasicConv2d(
      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_2): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_3): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch7x7x3_4): BasicConv2d(
      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7b): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (Mixed_7c): InceptionE(
    (branch1x1): BasicConv2d(
      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_1): BasicConv2d(
      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3_2b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_1): BasicConv2d(
      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_2): BasicConv2d(
      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3a): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch3x3dbl_3b): BasicConv2d(
      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch_pool): BasicConv2d(
      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fc): Linear(in_features=2048, out_features=3, bias=True)
)
Initializing Datasets and Dataloaders...
Params to learn:
	 Conv2d_1a_3x3.conv.weight
	 Conv2d_1a_3x3.bn.weight
	 Conv2d_1a_3x3.bn.bias
	 Conv2d_2a_3x3.conv.weight
	 Conv2d_2a_3x3.bn.weight
	 Conv2d_2a_3x3.bn.bias
	 Conv2d_2b_3x3.conv.weight
	 Conv2d_2b_3x3.bn.weight
	 Conv2d_2b_3x3.bn.bias
	 Conv2d_3b_1x1.conv.weight
	 Conv2d_3b_1x1.bn.weight
	 Conv2d_3b_1x1.bn.bias
	 Conv2d_4a_3x3.conv.weight
	 Conv2d_4a_3x3.bn.weight
	 Conv2d_4a_3x3.bn.bias
	 Mixed_5b.branch1x1.conv.weight
	 Mixed_5b.branch1x1.bn.weight
	 Mixed_5b.branch1x1.bn.bias
	 Mixed_5b.branch5x5_1.conv.weight
	 Mixed_5b.branch5x5_1.bn.weight
	 Mixed_5b.branch5x5_1.bn.bias
	 Mixed_5b.branch5x5_2.conv.weight
	 Mixed_5b.branch5x5_2.bn.weight
	 Mixed_5b.branch5x5_2.bn.bias
	 Mixed_5b.branch3x3dbl_1.conv.weight
	 Mixed_5b.branch3x3dbl_1.bn.weight
	 Mixed_5b.branch3x3dbl_1.bn.bias
	 Mixed_5b.branch3x3dbl_2.conv.weight
	 Mixed_5b.branch3x3dbl_2.bn.weight
	 Mixed_5b.branch3x3dbl_2.bn.bias
	 Mixed_5b.branch3x3dbl_3.conv.weight
	 Mixed_5b.branch3x3dbl_3.bn.weight
	 Mixed_5b.branch3x3dbl_3.bn.bias
	 Mixed_5b.branch_pool.conv.weight
	 Mixed_5b.branch_pool.bn.weight
	 Mixed_5b.branch_pool.bn.bias
	 Mixed_5c.branch1x1.conv.weight
	 Mixed_5c.branch1x1.bn.weight
	 Mixed_5c.branch1x1.bn.bias
	 Mixed_5c.branch5x5_1.conv.weight
	 Mixed_5c.branch5x5_1.bn.weight
	 Mixed_5c.branch5x5_1.bn.bias
	 Mixed_5c.branch5x5_2.conv.weight
	 Mixed_5c.branch5x5_2.bn.weight
	 Mixed_5c.branch5x5_2.bn.bias
	 Mixed_5c.branch3x3dbl_1.conv.weight
	 Mixed_5c.branch3x3dbl_1.bn.weight
	 Mixed_5c.branch3x3dbl_1.bn.bias
	 Mixed_5c.branch3x3dbl_2.conv.weight
	 Mixed_5c.branch3x3dbl_2.bn.weight
	 Mixed_5c.branch3x3dbl_2.bn.bias
	 Mixed_5c.branch3x3dbl_3.conv.weight
	 Mixed_5c.branch3x3dbl_3.bn.weight
	 Mixed_5c.branch3x3dbl_3.bn.bias
	 Mixed_5c.branch_pool.conv.weight
	 Mixed_5c.branch_pool.bn.weight
	 Mixed_5c.branch_pool.bn.bias
	 Mixed_5d.branch1x1.conv.weight
	 Mixed_5d.branch1x1.bn.weight
	 Mixed_5d.branch1x1.bn.bias
	 Mixed_5d.branch5x5_1.conv.weight
	 Mixed_5d.branch5x5_1.bn.weight
	 Mixed_5d.branch5x5_1.bn.bias
	 Mixed_5d.branch5x5_2.conv.weight
	 Mixed_5d.branch5x5_2.bn.weight
	 Mixed_5d.branch5x5_2.bn.bias
	 Mixed_5d.branch3x3dbl_1.conv.weight
	 Mixed_5d.branch3x3dbl_1.bn.weight
	 Mixed_5d.branch3x3dbl_1.bn.bias
	 Mixed_5d.branch3x3dbl_2.conv.weight
	 Mixed_5d.branch3x3dbl_2.bn.weight
	 Mixed_5d.branch3x3dbl_2.bn.bias
	 Mixed_5d.branch3x3dbl_3.conv.weight
	 Mixed_5d.branch3x3dbl_3.bn.weight
	 Mixed_5d.branch3x3dbl_3.bn.bias
	 Mixed_5d.branch_pool.conv.weight
	 Mixed_5d.branch_pool.bn.weight
	 Mixed_5d.branch_pool.bn.bias
	 Mixed_6a.branch3x3.conv.weight
	 Mixed_6a.branch3x3.bn.weight
	 Mixed_6a.branch3x3.bn.bias
	 Mixed_6a.branch3x3dbl_1.conv.weight
	 Mixed_6a.branch3x3dbl_1.bn.weight
	 Mixed_6a.branch3x3dbl_1.bn.bias
	 Mixed_6a.branch3x3dbl_2.conv.weight
	 Mixed_6a.branch3x3dbl_2.bn.weight
	 Mixed_6a.branch3x3dbl_2.bn.bias
	 Mixed_6a.branch3x3dbl_3.conv.weight
	 Mixed_6a.branch3x3dbl_3.bn.weight
	 Mixed_6a.branch3x3dbl_3.bn.bias
	 Mixed_6b.branch1x1.conv.weight
	 Mixed_6b.branch1x1.bn.weight
	 Mixed_6b.branch1x1.bn.bias
	 Mixed_6b.branch7x7_1.conv.weight
	 Mixed_6b.branch7x7_1.bn.weight
	 Mixed_6b.branch7x7_1.bn.bias
	 Mixed_6b.branch7x7_2.conv.weight
	 Mixed_6b.branch7x7_2.bn.weight
	 Mixed_6b.branch7x7_2.bn.bias
	 Mixed_6b.branch7x7_3.conv.weight
	 Mixed_6b.branch7x7_3.bn.weight
	 Mixed_6b.branch7x7_3.bn.bias
	 Mixed_6b.branch7x7dbl_1.conv.weight
	 Mixed_6b.branch7x7dbl_1.bn.weight
	 Mixed_6b.branch7x7dbl_1.bn.bias
	 Mixed_6b.branch7x7dbl_2.conv.weight
	 Mixed_6b.branch7x7dbl_2.bn.weight
	 Mixed_6b.branch7x7dbl_2.bn.bias
	 Mixed_6b.branch7x7dbl_3.conv.weight
	 Mixed_6b.branch7x7dbl_3.bn.weight
	 Mixed_6b.branch7x7dbl_3.bn.bias
	 Mixed_6b.branch7x7dbl_4.conv.weight
	 Mixed_6b.branch7x7dbl_4.bn.weight
	 Mixed_6b.branch7x7dbl_4.bn.bias
	 Mixed_6b.branch7x7dbl_5.conv.weight
	 Mixed_6b.branch7x7dbl_5.bn.weight
	 Mixed_6b.branch7x7dbl_5.bn.bias
	 Mixed_6b.branch_pool.conv.weight
	 Mixed_6b.branch_pool.bn.weight
	 Mixed_6b.branch_pool.bn.bias
	 Mixed_6c.branch1x1.conv.weight
	 Mixed_6c.branch1x1.bn.weight
	 Mixed_6c.branch1x1.bn.bias
	 Mixed_6c.branch7x7_1.conv.weight
	 Mixed_6c.branch7x7_1.bn.weight
	 Mixed_6c.branch7x7_1.bn.bias
	 Mixed_6c.branch7x7_2.conv.weight
	 Mixed_6c.branch7x7_2.bn.weight
	 Mixed_6c.branch7x7_2.bn.bias
	 Mixed_6c.branch7x7_3.conv.weight
	 Mixed_6c.branch7x7_3.bn.weight
	 Mixed_6c.branch7x7_3.bn.bias
	 Mixed_6c.branch7x7dbl_1.conv.weight
	 Mixed_6c.branch7x7dbl_1.bn.weight
	 Mixed_6c.branch7x7dbl_1.bn.bias
	 Mixed_6c.branch7x7dbl_2.conv.weight
	 Mixed_6c.branch7x7dbl_2.bn.weight
	 Mixed_6c.branch7x7dbl_2.bn.bias
	 Mixed_6c.branch7x7dbl_3.conv.weight
	 Mixed_6c.branch7x7dbl_3.bn.weight
	 Mixed_6c.branch7x7dbl_3.bn.bias
	 Mixed_6c.branch7x7dbl_4.conv.weight
	 Mixed_6c.branch7x7dbl_4.bn.weight
	 Mixed_6c.branch7x7dbl_4.bn.bias
	 Mixed_6c.branch7x7dbl_5.conv.weight
	 Mixed_6c.branch7x7dbl_5.bn.weight
	 Mixed_6c.branch7x7dbl_5.bn.bias
	 Mixed_6c.branch_pool.conv.weight
	 Mixed_6c.branch_pool.bn.weight
	 Mixed_6c.branch_pool.bn.bias
	 Mixed_6d.branch1x1.conv.weight
	 Mixed_6d.branch1x1.bn.weight
	 Mixed_6d.branch1x1.bn.bias
	 Mixed_6d.branch7x7_1.conv.weight
	 Mixed_6d.branch7x7_1.bn.weight
	 Mixed_6d.branch7x7_1.bn.bias
	 Mixed_6d.branch7x7_2.conv.weight
	 Mixed_6d.branch7x7_2.bn.weight
	 Mixed_6d.branch7x7_2.bn.bias
	 Mixed_6d.branch7x7_3.conv.weight
	 Mixed_6d.branch7x7_3.bn.weight
	 Mixed_6d.branch7x7_3.bn.bias
	 Mixed_6d.branch7x7dbl_1.conv.weight
	 Mixed_6d.branch7x7dbl_1.bn.weight
	 Mixed_6d.branch7x7dbl_1.bn.bias
	 Mixed_6d.branch7x7dbl_2.conv.weight
	 Mixed_6d.branch7x7dbl_2.bn.weight
	 Mixed_6d.branch7x7dbl_2.bn.bias
	 Mixed_6d.branch7x7dbl_3.conv.weight
	 Mixed_6d.branch7x7dbl_3.bn.weight
	 Mixed_6d.branch7x7dbl_3.bn.bias
	 Mixed_6d.branch7x7dbl_4.conv.weight
	 Mixed_6d.branch7x7dbl_4.bn.weight
	 Mixed_6d.branch7x7dbl_4.bn.bias
	 Mixed_6d.branch7x7dbl_5.conv.weight
	 Mixed_6d.branch7x7dbl_5.bn.weight
	 Mixed_6d.branch7x7dbl_5.bn.bias
	 Mixed_6d.branch_pool.conv.weight
	 Mixed_6d.branch_pool.bn.weight
	 Mixed_6d.branch_pool.bn.bias
	 Mixed_6e.branch1x1.conv.weight
	 Mixed_6e.branch1x1.bn.weight
	 Mixed_6e.branch1x1.bn.bias
	 Mixed_6e.branch7x7_1.conv.weight
	 Mixed_6e.branch7x7_1.bn.weight
	 Mixed_6e.branch7x7_1.bn.bias
	 Mixed_6e.branch7x7_2.conv.weight
	 Mixed_6e.branch7x7_2.bn.weight
	 Mixed_6e.branch7x7_2.bn.bias
	 Mixed_6e.branch7x7_3.conv.weight
	 Mixed_6e.branch7x7_3.bn.weight
	 Mixed_6e.branch7x7_3.bn.bias
	 Mixed_6e.branch7x7dbl_1.conv.weight
	 Mixed_6e.branch7x7dbl_1.bn.weight
	 Mixed_6e.branch7x7dbl_1.bn.bias
	 Mixed_6e.branch7x7dbl_2.conv.weight
	 Mixed_6e.branch7x7dbl_2.bn.weight
	 Mixed_6e.branch7x7dbl_2.bn.bias
	 Mixed_6e.branch7x7dbl_3.conv.weight
	 Mixed_6e.branch7x7dbl_3.bn.weight
	 Mixed_6e.branch7x7dbl_3.bn.bias
	 Mixed_6e.branch7x7dbl_4.conv.weight
	 Mixed_6e.branch7x7dbl_4.bn.weight
	 Mixed_6e.branch7x7dbl_4.bn.bias
	 Mixed_6e.branch7x7dbl_5.conv.weight
	 Mixed_6e.branch7x7dbl_5.bn.weight
	 Mixed_6e.branch7x7dbl_5.bn.bias
	 Mixed_6e.branch_pool.conv.weight
	 Mixed_6e.branch_pool.bn.weight
	 Mixed_6e.branch_pool.bn.bias
	 AuxLogits.conv0.conv.weight
	 AuxLogits.conv0.bn.weight
	 AuxLogits.conv0.bn.bias
	 AuxLogits.conv1.conv.weight
	 AuxLogits.conv1.bn.weight
	 AuxLogits.conv1.bn.bias
	 AuxLogits.fc.weight
	 AuxLogits.fc.bias
	 Mixed_7a.branch3x3_1.conv.weight
	 Mixed_7a.branch3x3_1.bn.weight
	 Mixed_7a.branch3x3_1.bn.bias
	 Mixed_7a.branch3x3_2.conv.weight
	 Mixed_7a.branch3x3_2.bn.weight
	 Mixed_7a.branch3x3_2.bn.bias
	 Mixed_7a.branch7x7x3_1.conv.weight
	 Mixed_7a.branch7x7x3_1.bn.weight
	 Mixed_7a.branch7x7x3_1.bn.bias
	 Mixed_7a.branch7x7x3_2.conv.weight
	 Mixed_7a.branch7x7x3_2.bn.weight
	 Mixed_7a.branch7x7x3_2.bn.bias
	 Mixed_7a.branch7x7x3_3.conv.weight
	 Mixed_7a.branch7x7x3_3.bn.weight
	 Mixed_7a.branch7x7x3_3.bn.bias
	 Mixed_7a.branch7x7x3_4.conv.weight
	 Mixed_7a.branch7x7x3_4.bn.weight
	 Mixed_7a.branch7x7x3_4.bn.bias
	 Mixed_7b.branch1x1.conv.weight
	 Mixed_7b.branch1x1.bn.weight
	 Mixed_7b.branch1x1.bn.bias
	 Mixed_7b.branch3x3_1.conv.weight
	 Mixed_7b.branch3x3_1.bn.weight
	 Mixed_7b.branch3x3_1.bn.bias
	 Mixed_7b.branch3x3_2a.conv.weight
	 Mixed_7b.branch3x3_2a.bn.weight
	 Mixed_7b.branch3x3_2a.bn.bias
	 Mixed_7b.branch3x3_2b.conv.weight
	 Mixed_7b.branch3x3_2b.bn.weight
	 Mixed_7b.branch3x3_2b.bn.bias
	 Mixed_7b.branch3x3dbl_1.conv.weight
	 Mixed_7b.branch3x3dbl_1.bn.weight
	 Mixed_7b.branch3x3dbl_1.bn.bias
	 Mixed_7b.branch3x3dbl_2.conv.weight
	 Mixed_7b.branch3x3dbl_2.bn.weight
	 Mixed_7b.branch3x3dbl_2.bn.bias
	 Mixed_7b.branch3x3dbl_3a.conv.weight
	 Mixed_7b.branch3x3dbl_3a.bn.weight
	 Mixed_7b.branch3x3dbl_3a.bn.bias
	 Mixed_7b.branch3x3dbl_3b.conv.weight
	 Mixed_7b.branch3x3dbl_3b.bn.weight
	 Mixed_7b.branch3x3dbl_3b.bn.bias
	 Mixed_7b.branch_pool.conv.weight
	 Mixed_7b.branch_pool.bn.weight
	 Mixed_7b.branch_pool.bn.bias
	 Mixed_7c.branch1x1.conv.weight
	 Mixed_7c.branch1x1.bn.weight
	 Mixed_7c.branch1x1.bn.bias
	 Mixed_7c.branch3x3_1.conv.weight
	 Mixed_7c.branch3x3_1.bn.weight
	 Mixed_7c.branch3x3_1.bn.bias
	 Mixed_7c.branch3x3_2a.conv.weight
	 Mixed_7c.branch3x3_2a.bn.weight
	 Mixed_7c.branch3x3_2a.bn.bias
	 Mixed_7c.branch3x3_2b.conv.weight
	 Mixed_7c.branch3x3_2b.bn.weight
	 Mixed_7c.branch3x3_2b.bn.bias
	 Mixed_7c.branch3x3dbl_1.conv.weight
	 Mixed_7c.branch3x3dbl_1.bn.weight
	 Mixed_7c.branch3x3dbl_1.bn.bias
	 Mixed_7c.branch3x3dbl_2.conv.weight
	 Mixed_7c.branch3x3dbl_2.bn.weight
	 Mixed_7c.branch3x3dbl_2.bn.bias
	 Mixed_7c.branch3x3dbl_3a.conv.weight
	 Mixed_7c.branch3x3dbl_3a.bn.weight
	 Mixed_7c.branch3x3dbl_3a.bn.bias
	 Mixed_7c.branch3x3dbl_3b.conv.weight
	 Mixed_7c.branch3x3dbl_3b.bn.weight
	 Mixed_7c.branch3x3dbl_3b.bn.bias
	 Mixed_7c.branch_pool.conv.weight
	 Mixed_7c.branch_pool.bn.weight
	 Mixed_7c.branch_pool.bn.bias
	 fc.weight
	 fc.bias
Epoch 0/99
----------
train Loss: 1.2197 Acc: 0.6079
val Loss: 6.5422 Acc: 0.3897

Epoch 1/99
----------
train Loss: 1.1071 Acc: 0.6347
val Loss: 0.6556 Acc: 0.7206

Epoch 2/99
----------
train Loss: 1.0148 Acc: 0.6798
val Loss: 0.6123 Acc: 0.7537

Epoch 3/99
----------
train Loss: 1.0002 Acc: 0.6832
val Loss: 0.7315 Acc: 0.5588

Epoch 4/99
----------
train Loss: 0.9654 Acc: 0.7016
val Loss: 1.0745 Acc: 0.5956

Epoch 5/99
----------
train Loss: 0.9328 Acc: 0.7191
val Loss: 0.4897 Acc: 0.8309

Epoch 6/99
----------
train Loss: 0.9203 Acc: 0.7214
val Loss: 0.4177 Acc: 0.8603

Epoch 7/99
----------
train Loss: 0.8827 Acc: 0.7340
val Loss: 0.5041 Acc: 0.8493

Epoch 8/99
----------
train Loss: 0.8771 Acc: 0.7312
val Loss: 0.4798 Acc: 0.8382

Epoch 9/99
----------
train Loss: 0.8523 Acc: 0.7386
val Loss: 0.5166 Acc: 0.8346

Epoch 10/99
----------
train Loss: 0.8476 Acc: 0.7415
val Loss: 0.5563 Acc: 0.7904

Epoch 11/99
----------
train Loss: 0.8272 Acc: 0.7446
val Loss: 0.6440 Acc: 0.7022

Epoch 12/99
----------
train Loss: 0.8207 Acc: 0.7511
val Loss: 0.4392 Acc: 0.8566

Epoch 13/99
----------
train Loss: 0.8172 Acc: 0.7478
val Loss: 0.5170 Acc: 0.8272

Epoch 14/99
----------
train Loss: 0.7797 Acc: 0.7611
val Loss: 0.4893 Acc: 0.8309

Epoch 15/99
----------
train Loss: 0.7875 Acc: 0.7653
val Loss: 0.3992 Acc: 0.8603

Epoch 16/99
----------
train Loss: 0.8104 Acc: 0.7574
val Loss: 0.4883 Acc: 0.8309

Epoch 17/99
----------
train Loss: 0.7557 Acc: 0.7670
val Loss: 0.5332 Acc: 0.8015

Epoch 18/99
----------
train Loss: 0.7714 Acc: 0.7709
val Loss: 0.5191 Acc: 0.8272

Epoch 19/99
----------
train Loss: 0.7702 Acc: 0.7705
val Loss: 0.4175 Acc: 0.8713

Epoch 20/99
----------
train Loss: 0.7663 Acc: 0.7718
val Loss: 0.5528 Acc: 0.7647

Epoch 21/99
----------
train Loss: 0.7577 Acc: 0.7659
val Loss: 0.4380 Acc: 0.8529

Epoch 22/99
----------
train Loss: 0.7613 Acc: 0.7678
val Loss: 0.4266 Acc: 0.8529

Epoch 23/99
----------
train Loss: 0.7449 Acc: 0.7697
val Loss: 0.3985 Acc: 0.8713

Epoch 24/99
----------
train Loss: 0.7491 Acc: 0.7720
val Loss: 0.3952 Acc: 0.8603

Epoch 25/99
----------
train Loss: 0.7215 Acc: 0.7826
val Loss: 0.6060 Acc: 0.7647

Epoch 26/99
----------
train Loss: 0.7403 Acc: 0.7687
val Loss: 0.5045 Acc: 0.7978

Epoch 27/99
----------
train Loss: 0.7455 Acc: 0.7691
val Loss: 0.4447 Acc: 0.8493

Epoch 28/99
----------
train Loss: 0.7206 Acc: 0.7787
val Loss: 0.4436 Acc: 0.8419

Epoch 29/99
----------
train Loss: 0.7179 Acc: 0.7802
val Loss: 0.4993 Acc: 0.8051

Epoch 30/99
----------
train Loss: 0.7386 Acc: 0.7774
val Loss: 0.4760 Acc: 0.8456

Epoch 31/99
----------
train Loss: 0.7288 Acc: 0.7791
val Loss: 0.5485 Acc: 0.7647

Epoch 32/99
----------
train Loss: 0.7146 Acc: 0.7781
val Loss: 0.4933 Acc: 0.8419

Epoch 33/99
----------
train Loss: 0.7008 Acc: 0.7856
val Loss: 0.3671 Acc: 0.8787

Epoch 34/99
----------
train Loss: 0.7083 Acc: 0.7810
val Loss: 0.4141 Acc: 0.8566

Epoch 35/99
----------
train Loss: 0.6902 Acc: 0.7893
val Loss: 0.3532 Acc: 0.8787

Epoch 36/99
----------
train Loss: 0.6876 Acc: 0.7895
val Loss: 0.3630 Acc: 0.8824

Epoch 37/99
----------
train Loss: 0.7028 Acc: 0.7887
val Loss: 0.3975 Acc: 0.8566

Epoch 38/99
----------
train Loss: 0.6846 Acc: 0.7910
val Loss: 0.4794 Acc: 0.7721

Epoch 39/99
----------
train Loss: 0.6749 Acc: 0.7965
val Loss: 0.4709 Acc: 0.8603

Epoch 40/99
----------
train Loss: 0.6738 Acc: 0.7893
val Loss: 0.3609 Acc: 0.8640

Epoch 41/99
----------
train Loss: 0.6758 Acc: 0.7829
val Loss: 0.4473 Acc: 0.8309

Epoch 42/99
----------
train Loss: 0.6771 Acc: 0.7939
val Loss: 0.3696 Acc: 0.8676

Epoch 43/99
----------
train Loss: 0.6553 Acc: 0.8012
val Loss: 0.4078 Acc: 0.8713

Epoch 44/99
----------
train Loss: 0.6567 Acc: 0.7979
val Loss: 0.3514 Acc: 0.8934

Epoch 45/99
----------
train Loss: 0.6703 Acc: 0.7904
val Loss: 0.3300 Acc: 0.8860

Epoch 46/99
----------
train Loss: 0.6612 Acc: 0.7933
val Loss: 0.3848 Acc: 0.8603

Epoch 47/99
----------
train Loss: 0.6508 Acc: 0.7977
val Loss: 0.4259 Acc: 0.8272

Epoch 48/99
----------
train Loss: 0.6513 Acc: 0.7985
val Loss: 0.3472 Acc: 0.8750

Epoch 49/99
----------
train Loss: 0.6527 Acc: 0.7975
val Loss: 0.4512 Acc: 0.7831

Epoch 50/99
----------
train Loss: 0.6468 Acc: 0.8021
val Loss: 0.3709 Acc: 0.8787

Epoch 51/99
----------
train Loss: 0.6513 Acc: 0.8019
val Loss: 0.3355 Acc: 0.8860

Epoch 52/99
----------
train Loss: 0.6491 Acc: 0.7994
val Loss: 0.4204 Acc: 0.8309

Epoch 53/99
----------
train Loss: 0.6357 Acc: 0.8073
val Loss: 0.4211 Acc: 0.8382

Epoch 54/99
----------
train Loss: 0.6253 Acc: 0.8094
val Loss: 0.3852 Acc: 0.8750

Epoch 55/99
----------
train Loss: 0.6123 Acc: 0.8138
val Loss: 0.4032 Acc: 0.8566

Epoch 56/99
----------
train Loss: 0.6472 Acc: 0.8025
val Loss: 0.5596 Acc: 0.7279

Epoch 57/99
----------
train Loss: 0.6154 Acc: 0.8104
val Loss: 0.4893 Acc: 0.8162

Epoch 58/99
----------
train Loss: 0.6230 Acc: 0.8058
val Loss: 0.3803 Acc: 0.8456

Epoch 59/99
----------
train Loss: 0.6287 Acc: 0.8069
val Loss: 0.3513 Acc: 0.9007

Epoch 60/99
----------
train Loss: 0.6089 Acc: 0.8138
val Loss: 0.3875 Acc: 0.8603

Epoch 61/99
----------
train Loss: 0.6106 Acc: 0.8075
val Loss: 0.3683 Acc: 0.8860

Epoch 62/99
----------
train Loss: 0.6121 Acc: 0.8142
val Loss: 0.5287 Acc: 0.7684

Epoch 63/99
----------
train Loss: 0.6024 Acc: 0.8155
val Loss: 0.3563 Acc: 0.8640

Epoch 64/99
----------
train Loss: 0.5956 Acc: 0.8161
val Loss: 0.3681 Acc: 0.8713

Epoch 65/99
----------
train Loss: 0.6095 Acc: 0.8159
val Loss: 0.2853 Acc: 0.9118

Epoch 66/99
----------
train Loss: 0.6007 Acc: 0.8163
val Loss: 0.3974 Acc: 0.8640

Epoch 67/99
----------
train Loss: 0.6044 Acc: 0.8163
val Loss: 0.3296 Acc: 0.8971

Epoch 68/99
----------
train Loss: 0.5988 Acc: 0.8199
val Loss: 0.3476 Acc: 0.8824

Epoch 69/99
----------
train Loss: 0.5855 Acc: 0.8136
val Loss: 0.3176 Acc: 0.8897

Epoch 70/99
----------
train Loss: 0.5916 Acc: 0.8192
val Loss: 0.2817 Acc: 0.8934

Epoch 71/99
----------
train Loss: 0.5710 Acc: 0.8244
val Loss: 0.4807 Acc: 0.8015

Epoch 72/99
----------
train Loss: 0.5779 Acc: 0.8265
val Loss: 0.3105 Acc: 0.8897

Epoch 73/99
----------
train Loss: 0.5913 Acc: 0.8188
val Loss: 0.3873 Acc: 0.8676

Epoch 74/99
----------
train Loss: 0.5853 Acc: 0.8226
val Loss: 0.3358 Acc: 0.8713

Epoch 75/99
----------
train Loss: 0.5689 Acc: 0.8230
val Loss: 0.4367 Acc: 0.8346

Epoch 76/99
----------
train Loss: 0.5507 Acc: 0.8337
val Loss: 0.3847 Acc: 0.8640

Epoch 77/99
----------
train Loss: 0.5759 Acc: 0.8238
val Loss: 0.4171 Acc: 0.8346

Epoch 78/99
----------
train Loss: 0.5652 Acc: 0.8272
val Loss: 0.4379 Acc: 0.8419

Epoch 79/99
----------
train Loss: 0.5708 Acc: 0.8270
val Loss: 0.3549 Acc: 0.8603

Epoch 80/99
----------
train Loss: 0.5593 Acc: 0.8259
val Loss: 0.3697 Acc: 0.8750

Epoch 81/99
----------
train Loss: 0.5489 Acc: 0.8320
val Loss: 0.3293 Acc: 0.8787

Epoch 82/99
----------
train Loss: 0.5305 Acc: 0.8418
val Loss: 0.3399 Acc: 0.8824

Epoch 83/99
----------
train Loss: 0.5649 Acc: 0.8286
val Loss: 0.3361 Acc: 0.8860

Epoch 84/99
----------
train Loss: 0.5572 Acc: 0.8311
val Loss: 0.3989 Acc: 0.8493

Epoch 85/99
----------
train Loss: 0.5464 Acc: 0.8384
val Loss: 0.3706 Acc: 0.8640

Epoch 86/99
----------
train Loss: 0.5518 Acc: 0.8299
val Loss: 0.3513 Acc: 0.8713

Epoch 87/99
----------
train Loss: 0.5428 Acc: 0.8284
val Loss: 0.3607 Acc: 0.8897

Epoch 88/99
----------
train Loss: 0.5493 Acc: 0.8372
val Loss: 0.3979 Acc: 0.8603

Epoch 89/99
----------
train Loss: 0.5330 Acc: 0.8330
val Loss: 0.3236 Acc: 0.9044

Epoch 90/99
----------
train Loss: 0.5471 Acc: 0.8307
val Loss: 0.3354 Acc: 0.8787

Epoch 91/99
----------
train Loss: 0.5371 Acc: 0.8372
val Loss: 0.3084 Acc: 0.8934

Epoch 92/99
----------
train Loss: 0.5229 Acc: 0.8384
val Loss: 0.3112 Acc: 0.9118

Epoch 93/99
----------
train Loss: 0.5260 Acc: 0.8353
val Loss: 0.3250 Acc: 0.8860

Epoch 94/99
----------
train Loss: 0.5148 Acc: 0.8456
val Loss: 0.3645 Acc: 0.8676

Epoch 95/99
----------
train Loss: 0.5312 Acc: 0.8405
val Loss: 0.3791 Acc: 0.8603

Epoch 96/99
----------
train Loss: 0.5315 Acc: 0.8374
val Loss: 0.3139 Acc: 0.8676

Epoch 97/99
----------
train Loss: 0.5089 Acc: 0.8433
val Loss: 0.2934 Acc: 0.9081

Epoch 98/99
----------
train Loss: 0.5290 Acc: 0.8370
val Loss: 0.3760 Acc: 0.8640

Epoch 99/99
----------
train Loss: 0.5101 Acc: 0.8445
val Loss: 0.3540 Acc: 0.8971

Training complete in 193m 53s
Best val Acc: 0.911765